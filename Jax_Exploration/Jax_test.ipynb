{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Jax?\n",
    "Jax is a Python library designed for high-performance ML research. Jax is nothing more than a numerical computing library, just like Numpy, but with some key improvements. It was developed by Google and used internally both by Google and Deepmind teams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jax basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.zeros(10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=jnp.zeros(10)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.8 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n",
      "72.7 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# Basics of jax\n",
    "x = np.random.rand(1000,1000)\n",
    "y = jnp.array(x)\n",
    "\n",
    "%timeit -n 1 -r 1 np.dot(x,x)\n",
    "# 1 loop, best of 1: 52.6 ms per loop\n",
    "\n",
    "%timeit -n 1 -r 1 jnp.dot(y,y).block_until_ready()\n",
    "# 1 loop, best of 1: 1.47 ms per loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calculations are faster in the GPUs. Also we need the block_until_ready() function. Because JAX is asynchronous, we need to wait until the execution is complete in order to properly measure the time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto differentiation with grad() function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### singular value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "from jax import grad\n",
    "def f(x):\n",
    "    return x**2+2*x+1\n",
    "def f_diff(x):\n",
    "    return 2*x+2\n",
    "print(grad(f)(1.0)) # grad return a derivative function \n",
    "print(f_diff(1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25       0.19661197 0.10499357]\n"
     ]
    }
   ],
   "source": [
    "def sum_logistic(x):\n",
    "  return jnp.sum(1.0 / (1.0 + jnp.exp(-x)))\n",
    "\n",
    "x_small = jnp.arange(3.)\n",
    "derivative_fn = grad(sum_logistic)\n",
    "print(derivative_fn(x_small))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return np.sum(jnp.power(x,2) + 2*x +1)  # f needs to have a scaler output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([2., 4., 6.], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad(f)(x_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand(1000,1000)  # even for matrix, just needs to explicitly address the position where we wanna differentiate\n",
    "y = jnp.array(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[3.5051565, 3.11126  , 3.457899 , ..., 3.4057453, 2.9257603,\n",
       "              2.1074712],\n",
       "             [2.4986985, 2.776178 , 2.7964032, ..., 2.7231436, 2.7258153,\n",
       "              2.4071379],\n",
       "             [3.6057768, 3.9050226, 2.598824 , ..., 3.2422433, 2.110405 ,\n",
       "              2.3537593],\n",
       "             ...,\n",
       "             [3.58633  , 3.0957935, 3.8398504, ..., 2.5640457, 2.6462164,\n",
       "              3.9038177],\n",
       "             [3.57158  , 2.1966538, 3.2050138, ..., 2.3495917, 2.3040285,\n",
       "              2.8068812],\n",
       "             [3.541185 , 3.4056678, 3.442199 , ..., 2.9499464, 2.4896505,\n",
       "              2.3615398]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad(f)(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accelerated Linear Algebra (XLA compiler)\n",
    "One of the factors that make JAX so fast is also Accelerated Linear Algebra or XLA.XLA is a domain-specific compiler for linear algebra that has been used extensively by Tensorflow.In order to perform matrix operations as fast as possible, the code is compiled into a set of computation kernels that can be extensively optimized based on the nature of the code.Just in time (jit) compilation comes hand in hand with XLA. In order to take advantage of the power of XLA, the code must be compiled into the XLA kernels. This is where jit comes into play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from jax import jit\n",
    "from jax import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175 ms ± 31.5 ms per loop (mean ± std. dev. of 5 runs, 5 loops each)\n",
      "47.9 ms ± 15.9 ms per loop (mean ± std. dev. of 5 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "x = np.random.rand(1000,1000)\n",
    "y = jnp.array(x)\n",
    "\n",
    "def f(x):\n",
    "\n",
    "  for _ in range(10):\n",
    "      x = 0.5*x + 0.1* jnp.sin(x)\n",
    "\n",
    "  return x\n",
    "\n",
    "g = jit(f)\n",
    "\n",
    "%timeit -n 5 -r 5 f(y).block_until_ready()\n",
    "# 5 loops, best of 5: 10.8 ms per loop\n",
    "\n",
    "%timeit -n 5 -r 5 g(y).block_until_ready()\n",
    "# 5 loops, best of 5: 341 µs per loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "jit can also be combined with grad transformation (or any other transformation for that matter), making backpropagation super fast.Pmap is another transformation that enables us to replicate the computation into multiple cores or devices and execute them in parallel(p in pmap stands for parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import pmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([0.        , 0.00580175, 0.01047094, 0.0139569 ], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(np.arange(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "compiling computation that requires 4 logical devices, but only 1 XLA devices are available (num_replicas=4, num_partitions=1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ebfcfce70923>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# no avialble devieces\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "    \u001b[0;31m[... skipping hidden 8 frame]\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/jax/interpreters/pxla.py\u001b[0m in \u001b[0;36mparallel_callable\u001b[0;34m(fun, backend_name, axis_name, axis_size, global_axis_size, devices, name, in_axes, out_axes_thunk, donated_invars, global_arg_shapes, *avals)\u001b[0m\n\u001b[1;32m    814\u001b[0m       msg = (\"compiling computation that requires {} logical devices, but only {} XLA \"\n\u001b[1;32m    815\u001b[0m              \"devices are available (num_replicas={}, num_partitions={})\")\n\u001b[0;32m--> 816\u001b[0;31m       raise ValueError(msg.format(num_global_shards, xb.device_count(backend),\n\u001b[0m\u001b[1;32m    817\u001b[0m                                   num_global_replicas, num_partitions))\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: compiling computation that requires 4 logical devices, but only 1 XLA devices are available (num_replicas=4, num_partitions=1)"
     ]
    }
   ],
   "source": [
    "pmap(f)(np.arange(4))# no avialble devieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([0.        , 0.00580175, 0.01047094, 0.0139569 , 0.01694178,\n",
       "             0.01998397, 0.02311684, 0.02610062, 0.02872661, 0.0309466 ],            dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jax import vmap\n",
    "f(jnp.arange(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatic vectorization with vmap\n",
    "Vmap is, as the name suggests, a function transformation that enables us to vectorize functions (v stands for vector!).\n",
    "We can take a function that operates on a single data point and vectorize it so it can accept a batch of these data points (or a vector) of arbitrary size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return vmap(f)(jnp.arange(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There have been already couple of popular libraries built on Jax\n",
    "* Haiku: Haiku is the go-to framework for Deep Learning and it’s used by many Google and Deepmind internal teams. It provides some simple, composable abstractions for machine learning research as well as ready-to-use modules and layers.\n",
    "\n",
    "* Optax: Optax is a gradient processing and optimization library that contains out-of-the-box optimizers and related mathematical operations.\n",
    "\n",
    "* RLax: RLax is a reinforcement learning framework with many RL subcomponents and operations.\n",
    "\n",
    "* Chex: Chex is a library of utilities for testing and debugging JAX code.\n",
    "\n",
    "* Jraph: Jraph is a Graph Neural Networks library in JAX.\n",
    "\n",
    "* Flax: Flax is another neural network library with a variety of ready-to-use modules, optimizers, and utilities. It’s most likely the closest we have in an all-in JAX framework.\n",
    "\n",
    "* Objax: Objax is a third ml library that focuses on object-oriented programming and code readability. Once again it contains the most popular modules, activation functions, losses, optimizers as well a handful of pre-trained models.\n",
    "\n",
    "* Trax: Trax is an end-to-end library for deep learning that focuses on Transformers\n",
    "\n",
    "* JAXline: JAXline is a supervised-learning library that is used for distributed JAX training and evaluation.\n",
    "\n",
    "* ACME: ACME is another research framework for reinforcement learning.\n",
    "\n",
    "* JAX-MD: JAX-MD is a niche framework that deals with molecular dynamics.\n",
    "\n",
    "* Jaxchem: JAXChem is another niche library that emphasizes on chemical modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Jax for a loss function autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stax is a small but flexible neural net specification library from scratch. :https://jax.readthedocs.io/en/latest/jax.experimental.stax.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler,Normalizer\n",
    "from sklearn.metrics import mean_absolute_error,mean_absolute_error\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import exp,log,sqrt\n",
    "from scipy import stats\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Black Scholes Put option and Greeks\n",
    "def bsput(s0,k,t,r,sigma):\n",
    "    \"\"\"\n",
    "    s0: spot price\n",
    "    k: strike\n",
    "    t: T-t maturity\n",
    "    r: risk free rate\n",
    "    sigma: volatility\n",
    "    y: dividend yield ==0\n",
    "    \"\"\"\n",
    "    d1=(log(s0/k)+(r+sigma**2/2)*t)/(sigma*sqrt(t))\n",
    "    d2=d1-sigma*sqrt(t)    \n",
    "    return -s0*norm.cdf(-d1)+k*exp(-r*t)*norm.cdf(-d2),s0*norm.pdf(d1)*t**0.5 \n",
    "\n",
    "def closedform_Euro(row):\n",
    "    return bsput(row['S'],row['K'],row['T'],row['rf'],row['Vol'])\n",
    "\n",
    "cdf = torch.distributions.Normal(0,1).cdf\n",
    "pdf = lambda x: torch.distributions.Normal(0,1).log_prob(x).exp()\n",
    "\n",
    "\n",
    "def bs_greeks(s0,k,t,r,sigma):\n",
    "    d1=(log(s0/k)+(r+sigma**2/2)*t)/(sigma*sqrt(t))\n",
    "    d2=d1-sigma*sqrt(t)\n",
    "    delta=-norm.cdf(-d1)\n",
    "    gamma=norm.pdf(d1)/s0/sigma/np.sqrt(t)\n",
    "    theta=-s0*sigma/2/np.sqrt(t) *norm.pdf(d1)+r*k*exp(-r*t)*norm.cdf(-d2)\n",
    "    return delta,gamma,theta\n",
    "\n",
    "def closedform_greeks(row):\n",
    "    return bs_greeks(row['S'],row['K'],row['T'],row['rf'],row['Vol'])\n",
    "\n",
    "def numerical_greeks(df_test):\n",
    "    \"\"\"\n",
    "    Input Dataframe:\n",
    "    S: spot price\n",
    "    Put_nn: estimated values from model\n",
    "    Delta: closed form\n",
    "    Gamma: closed form\n",
    "    \"\"\"\n",
    "    diff=df_test[['S','Put_nn']].sort_values('S').diff(1).dropna().reset_index(drop=True)\n",
    "    diff['Delta_c']=diff['Put_nn']/diff['S']\n",
    "    diff['Gamma']=diff['Delta_c'].diff(1)/diff['S'].shift(1)\n",
    "    \n",
    "    # Numerical & closed form Delta plot\n",
    "    plt.rcParams['agg.path.chunksize'] = 100000\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.scatter(df_test.sort_values('S')['S'][:-1],diff['Delta_c'].values, color='orange')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.scatter(df_test['S'],df_test['Delta'].values)\n",
    "    plt.show()\n",
    "    \n",
    "    # Numerical & closed form Gamma plot\n",
    "    plt.rcParams['agg.path.chunksize'] = 100000\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.scatter(df_test.sort_values('S')['S'][:-1],diff['Gamma'].values, color='orange')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.scatter(df_test['S'],df_test['Gamma'].values)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_train_data(n=250000, corner=False):\n",
    "    df=pd.DataFrame({\"S\":np.ones(n),\n",
    "                     \"K\":np.random.uniform(low=0.5,high=1.5,size=n),\n",
    "                     \"Vol\":np.random.uniform(low=0.1,high=0.4,size=n),\n",
    "              \"T\":np.random.uniform(low=0.25,high=2,size=n),\n",
    "                     \"rf\":np.random.uniform(low=0.0025,high=0.025,size=n)})\n",
    "    \n",
    "    if corner:\n",
    "        df_corner=pd.DataFrame({\"S\":np.ones(n),\n",
    "                         \"Vol\":np.ones(n)*0.2,\n",
    "                         \"T\":np.ones(n),\n",
    "                         \"rf\":np.ones(n)*0.01})\n",
    "\n",
    "        df_corner['K']=df_corner['S']*np.random.uniform(low=0.8,high=0.95,size=n) # special region\n",
    "        df = df.append(df_corner)\n",
    "\n",
    "    df[[\"Put\",\"Vega\"]]=df.apply(closedform_Euro, axis=1, result_type=\"expand\")\n",
    "\n",
    "    # weighted by T\n",
    "    df[\"Put\"] = df[\"Put\"]/df[\"K\"]/np.sqrt(df['T'])\n",
    "    df['K']=df['K']/np.sqrt(df['T'])\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50 * 30 * 7 * 10 = 105K\n",
    "def generate_mesh_train_data():\n",
    "    dimension = 5\n",
    "    K = 1\n",
    "    S = np.concatenate((np.linspace(1/0.5, 1/0.9, 20), np.linspace(1/0.8, 1/1.5, 20)), axis=None)\n",
    "    Vol = np.linspace(0.1, 0.4, 11)\n",
    "    T = np.concatenate((np.linspace(0.25, 1, 10), np.linspace(1, 2, 4)), axis=None)\n",
    "    rf = np.linspace(0.0025, 0.025, 11)\n",
    "    grid_data = np.stack(np.meshgrid(S, K, Vol, T, rf), dimension).reshape(-1, dimension)\n",
    "    df = pd.DataFrame(grid_data, columns=['S', 'K', 'Vol', 'T', 'rf'])\n",
    "    \n",
    "    df[[\"Put\", \"Vega\"]]=df.apply(closedform_Euro, axis=1, result_type=\"expand\")\n",
    "    df[\"Put\"] = df[\"Put\"]/df[\"K\"]/np.sqrt(df['T'])\n",
    "    df['K']=df['K']/np.sqrt(df['T'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_data(n=5000, dimension='K', low_bound=0.5, up_bound=1.5):\n",
    "    cdf = torch.distributions.Normal(0,1).cdf\n",
    "    pdf = lambda x: torch.distributions.Normal(0,1).log_prob(x).exp()\n",
    "\n",
    "    df=pd.DataFrame({\"S\":np.ones(n),\n",
    "                     \"K\":np.ones(n), \n",
    "                     \"Vol\":np.ones(n) * 0.2, \n",
    "                     \"T\":np.ones(n),\n",
    "                     \"rf\":np.ones(n) * 0.01})\n",
    "\n",
    "    df[dimension] = np.random.uniform(low=low_bound, high=up_bound, size=n)\n",
    "    df[[\"Put\",\"Vega\"]]=df.apply(closedform_Euro, axis=1, result_type=\"expand\")\n",
    "    \n",
    "    # weighted by T\n",
    "    df[\"Put\"] = df[\"Put\"]/df[\"K\"]/np.sqrt(df['T'])\n",
    "    df['K']=df['K']/np.sqrt(df['T'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_mesh_train_data()\n",
    "df_train = df.copy()\n",
    "df_train['Put'] = np.where(df_train['Put'] < 0.01, 0.01, df_train['Put'])\n",
    "\n",
    "y = df_train['Put']\n",
    "x = df_train.drop(['Put','Vega'], 1)\n",
    "\n",
    "x_train,x_test,y_train,y_test=model_selection.train_test_split(x,y,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.6.0-cp38-cp38-macosx_10_11_x86_64.whl (199.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 199.0 MB 448 kB/s eta 0:00:012\n",
      "\u001b[?25hCollecting tensorboard~=2.6\n",
      "  Downloading tensorboard-2.6.0-py3-none-any.whl (5.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.6 MB 2.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras~=2.6\n",
      "  Downloading keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 10.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: opt-einsum~=3.3.0 in /Users/supertt/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting wrapt~=1.12.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "Collecting termcolor~=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /Users/supertt/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.19.2)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 3.5 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions~=3.7.4 in /Users/supertt/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.7.4.3)\n",
      "Collecting clang~=5.0\n",
      "  Downloading clang-5.0.tar.gz (30 kB)\n",
      "Collecting gast==0.4.0\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting h5py~=3.1.0\n",
      "  Downloading h5py-3.1.0-cp38-cp38-macosx_10_9_x86_64.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 11.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six~=1.15.0 in /Users/supertt/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /Users/supertt/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.35.1)\n",
      "Requirement already satisfied: absl-py~=0.10 in /Users/supertt/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.13.0)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.17.3-cp38-cp38-macosx_10_9_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 13.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-pasta~=0.2\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 2.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting grpcio<2.0,>=1.37.0\n",
      "  Downloading grpcio-1.39.0-cp38-cp38-macosx_10_10_x86_64.whl (3.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.9 MB 12.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-estimator~=2.6\n",
      "  Downloading tensorflow_estimator-2.6.0-py2.py3-none-any.whl (462 kB)\n",
      "\u001b[K     |████████████████████████████████| 462 kB 15.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /Users/supertt/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (50.3.1.post20201107)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "\u001b[K     |████████████████████████████████| 781 kB 24.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 8.3 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.34.0-py2.py3-none-any.whl (152 kB)\n",
      "\u001b[K     |████████████████████████████████| 152 kB 16.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.5-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-macosx_10_9_x86_64.whl (3.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.5 MB 19.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /Users/supertt/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (2.24.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/supertt/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n",
      "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 19.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/supertt/opt/anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.2)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/supertt/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/supertt/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/supertt/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/supertt/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.25.11)\n",
      "Collecting pyasn1>=0.1.3\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 12.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "\u001b[K     |████████████████████████████████| 146 kB 12.6 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: wrapt, termcolor, clang\n",
      "  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wrapt: filename=wrapt-1.12.1-cp38-cp38-macosx_10_9_x86_64.whl size=32727 sha256=95cf0769e14e792a877b70e4e5165f2cbe61d138c5abf85fa2f4e2c8c0ddfb86\n",
      "  Stored in directory: /Users/supertt/Library/Caches/pip/wheels/5f/fd/9e/b6cf5890494cb8ef0b5eaff72e5d55a70fb56316007d6dfe73\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=83efdbccf7bf3ad385513a94803f2399434c561b8a22fba0a2d5ade288165913\n",
      "  Stored in directory: /Users/supertt/Library/Caches/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "  Building wheel for clang (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for clang: filename=clang-5.0-py3-none-any.whl size=30705 sha256=5ae92cfe3ae132a3e818b16597a8f5a8d97e0e8eb832195e371e763cb32ff5db\n",
      "  Stored in directory: /Users/supertt/Library/Caches/pip/wheels/f1/60/77/22b9b5887bd47801796a856f47650d9789c74dc3161a26d608\n",
      "Successfully built wrapt termcolor clang\n",
      "Installing collected packages: tensorboard-plugin-wit, markdown, pyasn1, rsa, pyasn1-modules, google-auth, grpcio, oauthlib, requests-oauthlib, google-auth-oauthlib, tensorboard-data-server, protobuf, tensorboard, keras, flatbuffers, wrapt, termcolor, keras-preprocessing, clang, gast, astunparse, h5py, google-pasta, tensorflow-estimator, tensorflow\n",
      "  Attempting uninstall: flatbuffers\n",
      "    Found existing installation: flatbuffers 2.0\n",
      "    Uninstalling flatbuffers-2.0:\n",
      "      Successfully uninstalled flatbuffers-2.0\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.11.2\n",
      "    Uninstalling wrapt-1.11.2:\n",
      "      Successfully uninstalled wrapt-1.11.2\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 2.10.0\n",
      "    Uninstalling h5py-2.10.0:\n",
      "      Successfully uninstalled h5py-2.10.0\n",
      "Successfully installed astunparse-1.6.3 clang-5.0 flatbuffers-1.12 gast-0.4.0 google-auth-1.34.0 google-auth-oauthlib-0.4.5 google-pasta-0.2.0 grpcio-1.39.0 h5py-3.1.0 keras-2.6.0 keras-preprocessing-1.1.2 markdown-3.3.4 oauthlib-3.1.1 protobuf-3.17.3 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.7.2 tensorboard-2.6.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.6.0 tensorflow-estimator-2.6.0 termcolor-1.1.0 wrapt-1.12.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import itertools\n",
    "\n",
    "import numpy.random as npr\n",
    "\n",
    "import jax.numpy as np\n",
    "from jax.config import config\n",
    "from jax import jit, grad, random\n",
    "from jax.experimental import optimizers\n",
    "from jax.experimental import stax\n",
    "from jax.experimental.stax import Dense, Relu, LogSoftmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(params, batch):\n",
    "    inputs, targets = batch\n",
    "    preds = predict(params, inputs)\n",
    "    return np.mean(np.sum((targets-preds)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_random_params, predict = stax.serial(\n",
    "    Dense(128), Relu,\n",
    "    Dense(1024), Relu,\n",
    "    Dense(128), Relu,\n",
    "    Dense(16),Relu,\n",
    "    Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size = 0.0001\n",
    "num_epochs = 80\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = x.shape[0]\n",
    "num_complete_batches, leftover = divmod(num_train, batch_size)\n",
    "num_batches = num_complete_batches + bool(leftover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = random.PRNGKey(0)\n",
    "def data_stream():\n",
    "    rng = npr.RandomState(0)    \n",
    "    while True:\n",
    "        perm = rng.permutation(num_train)\n",
    "        for i in range(num_batches):\n",
    "            batch_idx = perm[i * batch_size:(i + 1) * batch_size]\n",
    "            yield x.iloc[batch_idx,:].values, y.loc[batch_idx].values\n",
    "batches = data_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_init, opt_update, get_params = optimizers.adam(step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def update(i, opt_state, batch):\n",
    "    params = get_params(opt_state)\n",
    "    return opt_update(i, grad(loss)(params, batch), opt_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, init_params = init_random_params(rng, (-1, 5))\n",
    "opt_state = opt_init(init_params)\n",
    "itercount = itertools.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(params, inputs,targets):\n",
    "    preds=predict(params, inputs)\n",
    "    return np.mean(np.sum((preds-targets)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n",
      "Epoch 0 in 2.69 sec\n",
      "Epoch 1 in 1.01 sec\n",
      "Epoch 2 in 1.10 sec\n",
      "Epoch 3 in 1.14 sec\n",
      "Epoch 4 in 1.27 sec\n",
      "Epoch 5 in 1.35 sec\n",
      "Epoch 6 in 1.39 sec\n",
      "Epoch 7 in 1.44 sec\n",
      "Epoch 8 in 1.52 sec\n",
      "Epoch 9 in 1.59 sec\n",
      "Epoch 10 in 1.70 sec\n",
      "Epoch 11 in 1.82 sec\n",
      "Epoch 12 in 2.01 sec\n",
      "Epoch 13 in 2.09 sec\n",
      "Epoch 14 in 2.23 sec\n",
      "Epoch 15 in 2.45 sec\n",
      "Epoch 16 in 2.66 sec\n",
      "Epoch 17 in 2.88 sec\n",
      "Epoch 18 in 2.78 sec\n",
      "Epoch 19 in 2.67 sec\n",
      "Epoch 20 in 2.37 sec\n",
      "Epoch 21 in 1.99 sec\n",
      "Epoch 22 in 1.76 sec\n",
      "Epoch 23 in 1.61 sec\n",
      "Epoch 24 in 1.48 sec\n",
      "Epoch 25 in 1.53 sec\n",
      "Epoch 26 in 1.50 sec\n",
      "Epoch 27 in 1.46 sec\n",
      "Epoch 28 in 1.48 sec\n",
      "Epoch 29 in 1.47 sec\n",
      "Epoch 30 in 1.50 sec\n",
      "Epoch 31 in 1.49 sec\n",
      "Epoch 32 in 1.58 sec\n",
      "Epoch 33 in 1.49 sec\n",
      "Epoch 34 in 1.50 sec\n",
      "Epoch 35 in 1.53 sec\n",
      "Epoch 36 in 1.49 sec\n",
      "Epoch 37 in 1.47 sec\n",
      "Epoch 38 in 1.47 sec\n",
      "Epoch 39 in 1.45 sec\n",
      "Epoch 40 in 1.48 sec\n",
      "Epoch 41 in 1.45 sec\n",
      "Epoch 42 in 1.47 sec\n",
      "Epoch 43 in 1.46 sec\n",
      "Epoch 44 in 1.48 sec\n",
      "Epoch 45 in 1.48 sec\n",
      "Epoch 46 in 1.49 sec\n",
      "Epoch 47 in 1.49 sec\n",
      "Epoch 48 in 1.47 sec\n",
      "Epoch 49 in 1.48 sec\n",
      "Epoch 50 in 1.48 sec\n",
      "Epoch 51 in 1.49 sec\n",
      "Epoch 52 in 1.51 sec\n",
      "Epoch 53 in 1.56 sec\n",
      "Epoch 54 in 1.53 sec\n",
      "Epoch 55 in 1.52 sec\n",
      "Epoch 56 in 1.55 sec\n",
      "Epoch 57 in 1.55 sec\n",
      "Epoch 58 in 1.59 sec\n",
      "Epoch 59 in 1.65 sec\n",
      "Epoch 60 in 1.80 sec\n",
      "Epoch 61 in 1.72 sec\n",
      "Epoch 62 in 1.76 sec\n",
      "Epoch 63 in 1.72 sec\n",
      "Epoch 64 in 1.72 sec\n",
      "Epoch 65 in 1.68 sec\n",
      "Epoch 66 in 1.69 sec\n",
      "Epoch 67 in 1.69 sec\n",
      "Epoch 68 in 1.75 sec\n",
      "Epoch 69 in 1.79 sec\n",
      "Epoch 70 in 1.88 sec\n",
      "Epoch 71 in 1.84 sec\n",
      "Epoch 72 in 1.79 sec\n",
      "Epoch 73 in 1.80 sec\n",
      "Epoch 74 in 1.79 sec\n",
      "Epoch 75 in 1.82 sec\n",
      "Epoch 76 in 1.93 sec\n",
      "Epoch 77 in 1.84 sec\n",
      "Epoch 78 in 1.85 sec\n",
      "Epoch 79 in 1.89 sec\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStarting training...\")\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    for _ in range(num_batches):\n",
    "        opt_state = update(next(itercount), opt_state, next(batches))\n",
    "    epoch_time = time.time() - start_time    \n",
    "    params = get_params(opt_state)\n",
    "    #train_acc = accuracy(params, x.values, y.values)\n",
    "    print(\"Epoch {} in {:0.2f} sec\".format(epoch, epoch_time))\n",
    "    #print(\"Training set accuracy {}\".format(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(DeviceArray([[ 1.17039606e-01, -7.68911988e-02,  1.18306898e-01,\n",
       "                 2.35780347e-02, -5.23120090e-02,  1.06977083e-01,\n",
       "                 1.41145483e-01, -2.10290313e-01, -1.57700613e-01,\n",
       "                 5.40650003e-02, -1.46053582e-01,  2.11354256e-01,\n",
       "                 1.42893761e-01,  1.63040191e-01, -1.45566911e-01,\n",
       "                 9.56042483e-02, -6.05233619e-03,  3.44735198e-02,\n",
       "                -2.16554046e-01, -4.66052145e-02, -2.42987037e-01,\n",
       "                -1.14166282e-01, -6.64530396e-02, -1.80376954e-02,\n",
       "                -4.27191146e-02, -2.21430436e-01, -6.07723184e-02,\n",
       "                -1.72491953e-01, -1.02409251e-01,  4.93595675e-02,\n",
       "                -1.70862094e-01,  1.62178516e-01, -2.47168824e-01,\n",
       "                -1.55457556e-01,  7.87244141e-02,  7.37744523e-03,\n",
       "                 6.43459186e-02,  6.75803656e-03,  9.62769985e-02,\n",
       "                -3.75370979e-02, -1.88406020e-01, -1.08496837e-01,\n",
       "                 1.98165447e-01,  2.40025092e-02,  1.48074910e-01,\n",
       "                 1.55337334e-01, -1.30360112e-01, -6.72202557e-02,\n",
       "                -1.26325399e-01, -3.66527028e-02,  5.88572882e-02,\n",
       "                 6.35406747e-02, -2.67267749e-02, -2.87023395e-01,\n",
       "                -8.09899196e-02, -4.50216718e-02,  6.28312025e-03,\n",
       "                 1.01435065e-01,  1.82703529e-02,  3.24136280e-02,\n",
       "                -1.66075692e-01,  3.79926711e-02, -4.51232269e-02,\n",
       "                -4.31990996e-03, -1.45543128e-01, -9.02048126e-02,\n",
       "                -1.69121951e-01, -4.52147052e-02, -4.92260680e-02,\n",
       "                -1.27634406e-01,  1.88451987e-02,  1.23141659e-02,\n",
       "                 3.95320170e-02, -1.98332980e-01,  1.68931484e-02,\n",
       "                -1.05983177e-02, -8.85093361e-02, -8.16804096e-02,\n",
       "                 3.49783599e-02,  9.37344581e-02,  7.38385469e-02,\n",
       "                -1.42831430e-01, -3.72171821e-03,  2.35895105e-02,\n",
       "                 1.04287408e-01, -1.79846868e-01,  3.36165763e-02,\n",
       "                -1.34265702e-02, -8.01377073e-02, -5.47269955e-02,\n",
       "                 3.11539916e-04, -3.64624597e-02, -3.60302068e-02,\n",
       "                -8.22215378e-02, -1.80054918e-01, -9.69243497e-02,\n",
       "                -1.58758849e-01, -1.68768212e-01, -1.99047461e-01,\n",
       "                -1.78244635e-01, -6.45752624e-02, -1.47249848e-01,\n",
       "                -8.58814567e-02,  1.27717227e-01, -1.41185656e-01,\n",
       "                 1.29593983e-01,  2.50424631e-02,  9.93824974e-02,\n",
       "                -1.38757452e-01,  3.15816663e-02,  2.52372678e-02,\n",
       "                -1.45474477e-02, -1.49768993e-01, -1.14725344e-01,\n",
       "                -1.81424201e-01,  1.04098037e-01, -1.40707374e-01,\n",
       "                -7.51287192e-02,  4.57769968e-02,  1.24078818e-01,\n",
       "                -4.05257978e-02, -1.73240662e-01,  5.68374060e-02,\n",
       "                -1.36296049e-01, -5.42096980e-02,  5.39040603e-02,\n",
       "                -9.41382423e-02, -2.57672012e-01],\n",
       "               [-1.51731446e-01,  9.39356685e-02, -2.43551448e-01,\n",
       "                -3.49962674e-02, -1.04292735e-01, -3.09252478e-02,\n",
       "                 2.66139814e-05, -5.95975146e-02, -8.36430043e-02,\n",
       "                 6.14521839e-02,  1.07884914e-01,  1.51262462e-01,\n",
       "                -1.72948629e-01,  1.84952497e-01, -2.44756103e-01,\n",
       "                 2.26571839e-02,  7.23891109e-02, -5.29424362e-02,\n",
       "                -4.15641107e-02, -2.49665007e-01,  1.53916106e-01,\n",
       "                -9.11998823e-02, -9.25108939e-02, -4.22957428e-02,\n",
       "                 2.29014233e-01,  3.34906951e-02, -1.99544840e-02,\n",
       "                -9.82594341e-02,  1.30523324e-01,  3.85908037e-02,\n",
       "                 1.00040480e-01, -2.71641135e-01, -1.74354181e-01,\n",
       "                -2.49071959e-02, -4.41406108e-02, -7.54704028e-02,\n",
       "                -1.37895390e-01,  1.10246418e-02, -1.28518373e-01,\n",
       "                -1.29023388e-01,  2.25651301e-02,  3.25714797e-03,\n",
       "                -1.64325759e-02, -6.34696186e-02,  6.56418055e-02,\n",
       "                -2.44575348e-02, -1.47048011e-01,  9.77305993e-02,\n",
       "                -7.41830245e-02, -2.44988576e-01, -3.96879166e-02,\n",
       "                -4.21779193e-02, -6.42568171e-02, -5.45540042e-02,\n",
       "                -8.07791203e-02, -2.82236896e-02, -8.37860182e-02,\n",
       "                -2.97068059e-02, -1.48889124e-01,  1.55551925e-01,\n",
       "                -7.42172748e-02,  1.38210980e-02,  8.95752683e-02,\n",
       "                -1.20249592e-01,  2.87005994e-02,  4.15679179e-02,\n",
       "                -1.00584038e-01,  5.81151471e-02,  2.36320078e-01,\n",
       "                 3.57735418e-02, -9.50852633e-02, -2.43895501e-02,\n",
       "                -1.55545816e-01,  5.93785830e-02, -1.24715440e-01,\n",
       "                 8.95083398e-02,  6.36545941e-02,  2.45731488e-01,\n",
       "                -6.79813996e-02, -2.14788243e-01, -3.44820432e-02,\n",
       "                 1.14206202e-01, -5.73636405e-02, -7.87298083e-02,\n",
       "                 4.94262278e-02,  8.42500199e-03,  1.08090542e-01,\n",
       "                -6.16311058e-02, -9.35842842e-02,  3.98572460e-02,\n",
       "                -9.00877919e-03,  2.06624884e-02,  1.09096266e-01,\n",
       "                 8.57409984e-02,  3.68238352e-02, -1.53781801e-01,\n",
       "                -1.49610988e-03,  1.85690254e-01,  5.70980385e-02,\n",
       "                -1.15616463e-01,  3.82135473e-02,  8.55335370e-02,\n",
       "                -9.41183493e-02,  1.66391924e-01, -1.88664600e-01,\n",
       "                -1.72613457e-01,  3.02775968e-02, -1.22507937e-01,\n",
       "                 1.52790859e-01,  1.56127617e-01,  1.79453678e-02,\n",
       "                -6.83378875e-02, -1.62689269e-01,  6.20361865e-02,\n",
       "                -1.84196696e-01, -8.50979164e-02,  4.83818799e-02,\n",
       "                 7.49753937e-02, -8.87230784e-02, -1.12165019e-01,\n",
       "                 1.29561424e-01, -3.50724999e-03, -6.13248646e-02,\n",
       "                -4.95224446e-02, -1.57378301e-01,  3.11405994e-02,\n",
       "                -2.13412344e-01,  3.86062004e-02],\n",
       "               [-2.50975341e-01, -4.38769683e-02,  1.25531973e-02,\n",
       "                -4.16349387e-03, -1.88152716e-01, -1.93737373e-02,\n",
       "                 1.09450668e-01, -4.91396897e-02, -7.92161096e-03,\n",
       "                -6.08465672e-02,  1.30719896e-02,  4.90910634e-02,\n",
       "                -8.98981914e-02, -1.01456366e-01, -1.69084042e-01,\n",
       "                 1.53053835e-01, -9.84537974e-02, -1.21051595e-01,\n",
       "                -2.43831947e-01, -1.37452213e-02,  2.63129979e-01,\n",
       "                -2.14252308e-01, -1.11764960e-01,  1.09509461e-01,\n",
       "                 1.15131557e-01, -4.44580689e-02,  1.69430628e-01,\n",
       "                -2.13045031e-01,  2.22238928e-01, -9.28919986e-02,\n",
       "                -1.24612801e-01, -6.83251992e-02, -5.32718301e-02,\n",
       "                 1.07733727e-01, -1.14988893e-01, -5.64722680e-02,\n",
       "                 2.23946497e-02, -2.22513810e-01, -7.50690252e-02,\n",
       "                -2.00350851e-01, -5.56771085e-02,  4.07166071e-02,\n",
       "                 1.03699446e-01,  1.42965466e-01, -9.81983244e-02,\n",
       "                 1.29935384e-01,  1.06801972e-01, -1.03256792e-01,\n",
       "                -6.32074848e-02, -1.98778864e-02,  1.79653406e-01,\n",
       "                -2.69976228e-01, -2.56504640e-02,  1.23678140e-01,\n",
       "                 1.78694427e-02,  1.23416059e-01, -1.00089729e-01,\n",
       "                -1.76823556e-01,  7.30065033e-02, -1.61976635e-01,\n",
       "                -5.15245311e-02, -6.19956106e-02, -3.21233422e-02,\n",
       "                 1.28020043e-03, -5.79301491e-02,  5.61502352e-02,\n",
       "                -5.73537033e-03, -5.45076355e-02, -2.12883338e-01,\n",
       "                -2.51346529e-01,  1.28669038e-01,  5.81197590e-02,\n",
       "                -1.48863420e-01, -5.47817610e-02, -1.50733262e-01,\n",
       "                -1.23884186e-01,  1.12210552e-03, -5.69460355e-02,\n",
       "                 1.72315650e-02, -4.64358442e-02, -2.38737866e-01,\n",
       "                 8.97418782e-02,  8.43614936e-02,  6.07813932e-02,\n",
       "                -1.85976073e-01, -1.06729634e-01, -1.58534274e-01,\n",
       "                -3.84006575e-02, -4.82682437e-02, -2.21885536e-02,\n",
       "                -1.77131325e-01,  8.76384079e-02,  7.32451584e-03,\n",
       "                -3.22686099e-02,  4.79880609e-02,  2.57624481e-02,\n",
       "                 1.36574417e-01, -1.16302922e-01,  1.15746036e-01,\n",
       "                 1.43053800e-01, -3.40724201e-03,  9.57066342e-02,\n",
       "                 9.74195153e-02,  1.92995012e-01,  1.03584796e-01,\n",
       "                 2.30839159e-02,  1.57084689e-01,  1.69381201e-01,\n",
       "                 8.61887820e-03, -5.06474413e-02, -8.53170455e-02,\n",
       "                 3.01659573e-02,  1.50770545e-01,  1.07445113e-01,\n",
       "                -7.65041709e-02, -9.98192653e-03,  1.03184022e-01,\n",
       "                 6.84110001e-02, -5.31206578e-02, -2.41530776e-01,\n",
       "                -8.28498900e-02, -8.07240829e-02, -6.65909424e-02,\n",
       "                -1.81135833e-01,  5.53403683e-02,  1.41909331e-01,\n",
       "                 4.10588719e-02,  1.03492849e-01],\n",
       "               [ 6.63341209e-02, -1.88879088e-01,  5.23848832e-02,\n",
       "                 1.01606054e-02, -5.22961393e-02, -1.46251982e-02,\n",
       "                 6.43374398e-02, -1.62378892e-01,  6.56750575e-02,\n",
       "                -1.48409724e-01,  2.48266831e-02,  2.65828799e-02,\n",
       "                -2.00394094e-01,  1.23262368e-01,  7.30283111e-02,\n",
       "                -1.78026155e-01, -1.18668929e-01,  1.62833873e-02,\n",
       "                 1.61415488e-01, -2.64854199e-04,  1.05418757e-01,\n",
       "                 5.78073226e-02, -5.06631173e-02,  2.91175372e-03,\n",
       "                 1.42735556e-01, -3.35883498e-02, -4.33546007e-02,\n",
       "                 3.54893431e-02, -2.93614179e-01, -1.44352749e-01,\n",
       "                 8.49118829e-02,  2.55526658e-02,  3.85991372e-02,\n",
       "                 2.33974904e-02,  1.04185134e-01, -6.37536421e-02,\n",
       "                 1.05687320e-01,  6.30565407e-03,  1.46044254e-01,\n",
       "                 1.46301612e-01, -5.14091738e-02,  5.75337075e-02,\n",
       "                 2.48178393e-01, -2.37611798e-03, -1.80313617e-01,\n",
       "                 7.98943453e-03,  1.54775470e-01,  1.58307880e-01,\n",
       "                -1.29027218e-01,  1.93480045e-01, -1.19028434e-01,\n",
       "                -1.07428975e-01,  6.44526407e-02,  1.52427018e-01,\n",
       "                 2.12426797e-01,  2.28269860e-01,  5.42581156e-02,\n",
       "                 3.59023064e-02, -2.32994899e-01,  1.78954098e-02,\n",
       "                -1.68294191e-01,  7.34076798e-02, -1.27857774e-01,\n",
       "                 9.51587483e-02,  1.24878408e-02, -2.27911308e-01,\n",
       "                 1.37583286e-01, -9.03381314e-03,  2.09906295e-01,\n",
       "                -6.60108998e-02,  1.60126500e-02,  3.82466638e-03,\n",
       "                 7.45689720e-02, -8.69306475e-02,  1.38039708e-01,\n",
       "                -1.26222491e-01,  4.97811027e-02, -3.25893089e-02,\n",
       "                 1.80868860e-02,  1.60897270e-01,  7.18379840e-02,\n",
       "                 1.13853201e-01, -1.01176113e-01,  4.31772955e-02,\n",
       "                -5.36609106e-02,  8.33499730e-02,  1.47372261e-01,\n",
       "                -7.27961287e-02,  1.24172136e-01, -8.11166838e-02,\n",
       "                 1.74887791e-01,  2.77023856e-02,  1.90577693e-02,\n",
       "                -7.30584487e-02, -4.23431545e-02, -2.02001259e-01,\n",
       "                 1.31962579e-02,  1.03323869e-02, -1.12785853e-01,\n",
       "                -1.16499148e-01,  1.99263528e-01, -9.00662094e-02,\n",
       "                 1.63862154e-01, -1.41731706e-02, -4.23621833e-02,\n",
       "                 5.37998006e-02, -1.35118455e-01, -1.28148897e-02,\n",
       "                -1.19471483e-01, -2.60742396e-01, -5.16632497e-02,\n",
       "                 1.82694525e-01,  6.02760315e-02,  2.89564580e-02,\n",
       "                -9.29562096e-03, -7.18196109e-02,  6.48621395e-02,\n",
       "                -3.23995389e-03, -2.85608657e-02,  7.98842385e-02,\n",
       "                -2.22586825e-01, -9.36575979e-03,  3.68183739e-02,\n",
       "                -3.10489535e-02,  9.41740274e-02, -1.55793831e-01,\n",
       "                 2.49245778e-01, -9.85408127e-02],\n",
       "               [-9.94665101e-02, -2.01719984e-01,  1.78451270e-01,\n",
       "                -1.32802084e-01,  1.42861202e-01,  1.05572954e-01,\n",
       "                 2.58060079e-02, -7.43400976e-02, -1.81880921e-01,\n",
       "                -3.14064622e-02,  7.22502023e-02, -1.55060785e-02,\n",
       "                -4.34262194e-02,  1.72030538e-01, -1.18454315e-01,\n",
       "                -1.16729833e-01,  3.41968723e-02, -1.66652307e-01,\n",
       "                -9.44129527e-02, -1.60226300e-02,  6.34445101e-02,\n",
       "                 4.42912988e-02,  1.19337559e-01, -9.25306380e-02,\n",
       "                 7.14579374e-02, -7.09461644e-02, -7.97945634e-02,\n",
       "                -1.40067963e-02,  2.52754390e-01, -2.04429239e-01,\n",
       "                -3.61350104e-02, -8.00466090e-02,  2.37129368e-02,\n",
       "                -8.43905360e-02, -1.85644791e-01,  1.45544901e-01,\n",
       "                -3.30472052e-01, -8.24101493e-02,  2.42709428e-01,\n",
       "                -1.05689161e-01, -6.45610616e-02, -3.46169770e-02,\n",
       "                 1.13623738e-02,  7.41352439e-02, -1.09988250e-01,\n",
       "                 2.90054791e-02, -1.58816278e-01, -1.31945431e-01,\n",
       "                -2.46172082e-02, -1.32168308e-01,  5.32749258e-02,\n",
       "                -6.89324364e-02, -3.54345031e-02,  5.64505272e-02,\n",
       "                 9.85465571e-02, -9.73684639e-02, -9.54451486e-02,\n",
       "                -1.26668632e-01, -1.63286924e-01, -2.26283729e-01,\n",
       "                -6.21723384e-02, -5.97865134e-02, -2.56235778e-01,\n",
       "                 1.67563632e-01, -1.05960406e-01,  3.49040702e-02,\n",
       "                -4.08533961e-02, -8.42245072e-02,  1.72589839e-01,\n",
       "                -6.48172796e-02,  3.93671952e-02, -1.12826273e-01,\n",
       "                 1.03499882e-01, -1.02086037e-01,  2.42990047e-01,\n",
       "                -2.23155335e-01, -3.75378802e-02, -6.29300475e-02,\n",
       "                -1.43902808e-01,  1.23060241e-01,  2.42771264e-02,\n",
       "                -8.37097540e-02, -4.84472979e-03, -2.30632633e-01,\n",
       "                -2.50121981e-01, -1.06027529e-01,  1.83797926e-01,\n",
       "                -3.59129123e-02, -1.03218660e-01,  1.02685943e-01,\n",
       "                 3.29919420e-02, -2.60221153e-01, -5.97943105e-02,\n",
       "                -6.79555759e-02, -2.38204524e-02,  2.77716685e-02,\n",
       "                 1.38150275e-01, -2.64466088e-02,  1.48916647e-01,\n",
       "                -2.88093332e-02, -2.56999165e-01, -5.33206686e-02,\n",
       "                 4.08530198e-02, -4.59454358e-02,  4.07736041e-02,\n",
       "                -7.27090910e-02,  1.46596670e-01,  9.14690122e-02,\n",
       "                -1.82208747e-01,  1.26081869e-01,  4.59262542e-02,\n",
       "                 5.78187034e-02, -1.35012910e-01, -1.14141680e-01,\n",
       "                 9.93918031e-02, -2.02541992e-01,  1.86701685e-01,\n",
       "                 1.75796762e-01,  9.13606882e-02, -2.54727632e-01,\n",
       "                 1.05683587e-01,  1.04576750e-02, -7.86520466e-02,\n",
       "                 2.47415945e-01,  4.11887467e-02,  2.41167787e-02,\n",
       "                -6.31664097e-02, -1.58795416e-01]], dtype=float32),\n",
       "  DeviceArray([-6.94399583e-04, -9.24518704e-03,  5.53361606e-03,\n",
       "               -4.23438288e-02,  5.14567737e-03, -3.56398188e-02,\n",
       "               -2.69495472e-02,  2.52399687e-03, -1.24933887e-02,\n",
       "               -8.65001529e-02,  1.26815224e-02, -4.96745706e-02,\n",
       "                1.51740313e-02, -5.05328774e-02,  1.04451012e-02,\n",
       "               -2.64984816e-02, -5.30502908e-02, -2.62100380e-02,\n",
       "               -6.97608963e-02, -2.36008540e-02,  1.37037672e-02,\n",
       "               -1.96907930e-02,  4.76380531e-03, -8.85702390e-03,\n",
       "               -2.22685579e-02, -1.81772839e-02,  7.42677972e-03,\n",
       "               -1.54927354e-02, -1.73171572e-02, -1.48084573e-02,\n",
       "                3.62472818e-03,  5.68688475e-03, -1.08681899e-02,\n",
       "                7.85703491e-03, -1.61097050e-02, -1.02990824e-04,\n",
       "               -1.05723299e-01, -1.47460205e-02, -2.45012958e-02,\n",
       "                1.68884173e-03, -4.60133608e-03, -4.29426357e-02,\n",
       "               -3.14588174e-02, -5.78924343e-02, -1.06240712e-01,\n",
       "               -3.03811096e-02, -5.84586710e-02, -1.66083046e-04,\n",
       "                4.46835952e-03,  7.47358752e-03, -1.54336719e-02,\n",
       "               -7.72640016e-03, -2.37360653e-02, -6.65311292e-02,\n",
       "               -2.16477290e-02,  8.63965787e-03, -1.41167548e-02,\n",
       "               -2.62143947e-02, -9.24137607e-03, -1.11217275e-02,\n",
       "                1.22044506e-02, -5.71062379e-02, -4.61325049e-02,\n",
       "               -6.78624734e-02,  8.19570385e-03,  8.70022364e-03,\n",
       "               -8.17424338e-03, -7.93752894e-02, -2.41437014e-02,\n",
       "               -6.29128842e-03, -4.15114984e-02, -3.83144468e-02,\n",
       "               -7.84087740e-03,  1.81378555e-02, -1.21636307e-02,\n",
       "               -6.87285438e-02,  2.10920512e-03, -2.03508995e-02,\n",
       "               -3.48872468e-02,  3.29342205e-03, -4.29835245e-02,\n",
       "                1.02607030e-02,  2.87602050e-03, -6.12335838e-02,\n",
       "               -8.79310369e-02, -1.96607802e-02, -2.46828459e-02,\n",
       "               -1.02954898e-02, -2.35072095e-02, -2.54426897e-02,\n",
       "                2.20840471e-03, -3.62276882e-02, -4.71354239e-02,\n",
       "               -2.42077019e-02,  1.26107438e-02, -1.10381506e-02,\n",
       "                6.59507641e-04, -1.36358608e-02, -4.40140255e-03,\n",
       "               -9.67619196e-03, -3.25464495e-02, -2.66794618e-02,\n",
       "               -1.76294334e-02, -7.66711608e-02,  1.13935741e-02,\n",
       "                2.92526954e-03, -6.52060136e-02, -1.88656766e-02,\n",
       "               -3.97482701e-02, -9.96405855e-02, -4.32823822e-02,\n",
       "               -5.18339612e-02,  6.86541758e-03, -1.34763401e-02,\n",
       "                1.59614794e-02,  3.35599063e-03, -6.42631017e-03,\n",
       "               -5.36211650e-04,  1.83979999e-02, -6.77340552e-02,\n",
       "               -2.09499672e-02, -1.07530374e-02, -7.79043585e-02,\n",
       "               -5.94336120e-03, -4.04284988e-03, -4.33855094e-02,\n",
       "                4.27603396e-03, -5.63589856e-03], dtype=float32)),\n",
       " (),\n",
       " (DeviceArray([[ 5.6542852e-03,  2.3040511e-02, -6.3437778e-03, ...,\n",
       "                 2.2918344e-02, -3.3910985e-06,  2.8468017e-02],\n",
       "               [-1.5685390e-04,  4.0832449e-02,  1.1133657e-02, ...,\n",
       "                -1.6439524e-02,  7.8313142e-02,  5.0977860e-02],\n",
       "               [-3.7203331e-02,  3.1624947e-02, -1.3179759e-02, ...,\n",
       "                 3.3740945e-02, -3.6089148e-03,  2.9740410e-03],\n",
       "               ...,\n",
       "               [ 6.1611466e-02, -1.3403105e-02,  6.1208494e-02, ...,\n",
       "                -2.1257784e-02,  5.3463288e-02, -5.9290059e-02],\n",
       "               [ 4.2110711e-02,  2.0465834e-02,  5.7547554e-02, ...,\n",
       "                -4.8624791e-02, -4.5021549e-02, -3.6339283e-03],\n",
       "               [-4.2443699e-03, -2.8546198e-04,  2.0715317e-02, ...,\n",
       "                -7.1683805e-03, -6.3926391e-02, -5.3729896e-02]],            dtype=float32),\n",
       "  DeviceArray([-0.00985225, -0.00815373,  0.01105975, ..., -0.0003955 ,\n",
       "               -0.02341297, -0.00267856], dtype=float32)),\n",
       " (),\n",
       " (DeviceArray([[-9.5423236e-03,  1.6781347e-02, -1.7933600e-02, ...,\n",
       "                 1.2429600e-02, -3.6292583e-02,  1.9528860e-02],\n",
       "               [-3.1364392e-02, -1.5293453e-04,  1.4323551e-02, ...,\n",
       "                -1.2988739e-02,  1.4322758e-02, -1.9562580e-02],\n",
       "               [ 2.6641766e-02,  5.3125978e-03,  1.6186493e-02, ...,\n",
       "                -1.9126197e-02, -3.3431701e-02,  9.1654016e-03],\n",
       "               ...,\n",
       "               [-3.2075953e-02,  2.4716627e-02, -8.8489754e-03, ...,\n",
       "                -3.3583663e-02, -2.0221859e-02,  8.2423910e-03],\n",
       "               [-5.9068602e-02,  2.1155294e-02, -1.5142073e-02, ...,\n",
       "                -1.4992285e-02,  2.2685127e-02,  1.0051702e-05],\n",
       "               [-1.8609051e-02,  2.7160272e-02, -4.4007793e-02, ...,\n",
       "                 2.5272842e-03, -1.2933611e-02, -8.4710186e-03]],            dtype=float32),\n",
       "  DeviceArray([ 1.19469808e-02, -8.30619410e-03,  2.15934422e-02,\n",
       "               -7.00704614e-03,  2.42559779e-02, -1.11466926e-02,\n",
       "               -1.11623723e-02, -1.99083984e-02, -2.70275306e-02,\n",
       "                1.16695103e-03, -1.21725509e-02,  1.55105125e-02,\n",
       "                3.33728176e-03,  2.77362508e-03,  5.02399169e-04,\n",
       "               -5.36749838e-03, -8.40557832e-03,  9.42781940e-03,\n",
       "               -2.84763966e-02, -8.00116267e-03, -1.10398429e-02,\n",
       "                1.83696356e-02, -1.33286351e-02, -6.41217502e-03,\n",
       "                6.70303052e-05, -7.07130041e-03, -1.44038014e-02,\n",
       "                2.99174525e-03,  2.11873669e-02,  6.12929929e-03,\n",
       "                1.33138392e-02, -2.22183801e-02, -4.77088057e-03,\n",
       "               -2.02850550e-02, -2.88027022e-02,  4.52612061e-03,\n",
       "                2.42448803e-02, -1.25261245e-03, -2.50082910e-02,\n",
       "               -7.81957700e-04, -1.25921296e-03, -1.17337285e-02,\n",
       "                3.85768153e-02, -7.86624663e-03, -1.68132391e-02,\n",
       "               -2.73017921e-02,  2.27663163e-02, -6.55081728e-03,\n",
       "                7.02182902e-03, -3.40927625e-03,  2.64430768e-03,\n",
       "                3.27940434e-02, -9.12846159e-03, -1.99273340e-02,\n",
       "                1.68023305e-03, -1.93632916e-02, -2.00013653e-03,\n",
       "                4.14829217e-02,  1.87038239e-02, -6.87017245e-03,\n",
       "               -1.37574542e-02,  1.86470915e-02, -4.83131874e-03,\n",
       "                1.40199845e-03,  3.70167159e-02, -1.12478575e-02,\n",
       "               -2.66426969e-02, -1.49504971e-02,  1.15042934e-02,\n",
       "               -3.47028784e-02, -3.18215135e-03, -4.92101954e-03,\n",
       "               -2.47089309e-03, -3.20084440e-03, -2.05778889e-02,\n",
       "               -1.02495560e-02, -3.25201033e-03, -7.90938921e-03,\n",
       "               -1.77620314e-02,  5.50363213e-03,  1.11947386e-02,\n",
       "                5.46708843e-03,  2.17327196e-02,  1.82376313e-03,\n",
       "                1.22973397e-02, -1.80589370e-02, -2.68547144e-03,\n",
       "               -2.19547786e-02,  2.91844122e-02, -2.25104932e-02,\n",
       "               -2.04695426e-02, -2.15601940e-02,  1.81098487e-02,\n",
       "               -1.56055402e-03, -3.19103748e-02, -7.12085469e-03,\n",
       "               -7.28097837e-03, -1.73064731e-02,  6.42922168e-05,\n",
       "               -4.00581630e-03, -1.79828256e-02, -6.77895639e-03,\n",
       "               -1.84979085e-02, -2.34472156e-02, -1.33264388e-04,\n",
       "               -2.57323729e-03, -1.21450266e-02, -1.57802198e-02,\n",
       "                7.33450055e-03,  1.88108510e-03, -6.51935069e-03,\n",
       "               -1.32636679e-02, -4.46895091e-03, -1.65900961e-02,\n",
       "               -1.12036150e-02, -1.33451810e-02, -2.42253356e-02,\n",
       "               -8.85946397e-03,  1.47085069e-02, -1.22497967e-02,\n",
       "               -3.54672223e-03, -4.06627951e-04,  4.22070269e-03,\n",
       "               -2.93240370e-03, -1.03497887e-02,  2.26119291e-02,\n",
       "               -4.30061668e-03, -1.12823164e-02], dtype=float32)),\n",
       " (),\n",
       " (DeviceArray([[-0.12203434,  0.00430078, -0.07474279, ...,  0.07175025,\n",
       "                -0.09296209, -0.17794923],\n",
       "               [ 0.07113116,  0.01871429, -0.02113151, ..., -0.00374303,\n",
       "                 0.09754235, -0.05606188],\n",
       "               [ 0.17218643, -0.12364091, -0.20070031, ...,  0.14177996,\n",
       "                 0.07822929,  0.06637567],\n",
       "               ...,\n",
       "               [ 0.08124176, -0.00492191, -0.20803112, ...,  0.22436132,\n",
       "                -0.0875618 ,  0.0547209 ],\n",
       "               [ 0.14887962,  0.1091899 ,  0.12128041, ..., -0.15501758,\n",
       "                -0.09100594, -0.10516467],\n",
       "               [ 0.13575374, -0.15635532, -0.24105048, ...,  0.132342  ,\n",
       "                -0.09447233,  0.11289068]], dtype=float32),\n",
       "  DeviceArray([-0.00804594, -0.00812045,  0.03926263, -0.01288298,\n",
       "                0.01166933, -0.01332716, -0.01274962, -0.02040181,\n",
       "                0.03229002, -0.01002865, -0.01606747, -0.00823424,\n",
       "               -0.00212161,  0.02057358,  0.01147389, -0.01242591],            dtype=float32)),\n",
       " (),\n",
       " (DeviceArray([[ 0.08679051],\n",
       "               [-0.01747634],\n",
       "               [ 0.11272755],\n",
       "               [-0.69010854],\n",
       "               [ 0.33771455],\n",
       "               [-0.05189151],\n",
       "               [-0.00322326],\n",
       "               [-0.20671976],\n",
       "               [ 0.11965039],\n",
       "               [-0.33610737],\n",
       "               [-0.05792254],\n",
       "               [-0.39581543],\n",
       "               [-0.33432952],\n",
       "               [ 0.48995456],\n",
       "               [-0.13880654],\n",
       "               [ 0.09657578]], dtype=float32),\n",
       "  DeviceArray([0.03196412], dtype=float32))]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_params(opt_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[0.09021164],\n",
       "             [0.09021601],\n",
       "             [0.09022038],\n",
       "             ...,\n",
       "             [0.09159355],\n",
       "             [0.09159149],\n",
       "             [0.09158941]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(get_params(opt_state), x.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/deepmind/dm-haiku\n",
      "  Cloning https://github.com/deepmind/dm-haiku to /private/var/folders/wm/m4whmdd14n57n775j15v1tjw0000gn/T/pip-req-build-msvcx1vm\n",
      "Requirement already satisfied: absl-py>=0.7.1 in /Users/supertt/opt/anaconda3/lib/python3.8/site-packages (from dm-haiku==0.0.5.dev0) (0.13.0)\n",
      "Collecting jmp>=0.0.2\n",
      "  Downloading jmp-0.0.2-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /Users/supertt/opt/anaconda3/lib/python3.8/site-packages (from dm-haiku==0.0.5.dev0) (1.19.2)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /Users/supertt/opt/anaconda3/lib/python3.8/site-packages (from dm-haiku==0.0.5.dev0) (0.8.9)\n",
      "Requirement already satisfied: six in /Users/supertt/opt/anaconda3/lib/python3.8/site-packages (from absl-py>=0.7.1->dm-haiku==0.0.5.dev0) (1.15.0)\n",
      "Building wheels for collected packages: dm-haiku\n",
      "  Building wheel for dm-haiku (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dm-haiku: filename=dm_haiku-0.0.5.dev0-py3-none-any.whl size=285278 sha256=6bcb0bcc6bc2b3558fea688ed76fc8c735df535ad07eef3329f59fb130196f53\n",
      "  Stored in directory: /private/var/folders/wm/m4whmdd14n57n775j15v1tjw0000gn/T/pip-ephem-wheel-cache-8b1_z6vp/wheels/c7/4d/89/b159f184ad7c9e95672c342eafcc176ad92ee0c77f27f3bd23\n",
      "Successfully built dm-haiku\n",
      "Installing collected packages: jmp, dm-haiku\n",
      "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "jmp 0.0.2 requires numpy>=1.19.5, but you'll have numpy 1.19.2 which is incompatible.\u001b[0m\n",
      "Successfully installed dm-haiku-0.0.5.dev0 jmp-0.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/deepmind/dm-haiku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import haiku as hk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(x_train,y_train):\n",
    "    mlp = hk.Sequential([hk.Linear(128), jax.nn.relu,\n",
    "                         hk.Linear(1024), jax.nn.relu,\n",
    "                         hk.Linear(128),  jax.nn.relu,\n",
    "                         hk.Linear(16), jax.nn.celu,\n",
    "                         hk.Linear(1)])\n",
    "    preds = mlp(x_train)\n",
    "    return jnp.mean(jnp.sum(preds-y_train)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/supertt/opt/anaconda3/lib/python3.8/site-packages/jax/_src/numpy/lax_numpy.py:3133: UserWarning: Explicitly requested dtype float64 requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  lax._check_user_dtype_supported(dtype, \"zeros\")\n"
     ]
    }
   ],
   "source": [
    "loss_fn_t = hk.transform(loss_fn)\n",
    "loss_fn_t = hk.without_apply_rng(loss_fn_t)\n",
    "# Initial parameter values are typically random. In JAX you need a key in order\n",
    "# to generate random numbers and so Haiku requires you to pass one in.\n",
    "rng = jax.random.PRNGKey(42)\n",
    "\n",
    "# `init` runs your function, as such we need an example input. Typically you can\n",
    "# pass \"dummy\" inputs (e.g. ones of the same shape and dtype) since initialization\n",
    "# is not usually data dependent.\n",
    "x_init, y_init = next(batches)\n",
    "\n",
    "# The result of `init` is a nested data structure of all the parameters in your\n",
    "# network. You can pass this into `apply`.\n",
    "params = loss_fn_t.init(rng, x_init, y_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FlatMap({\n",
       "  'linear': FlatMap({\n",
       "              'w': DeviceArray([[-0.4363558 ,  0.0706057 ,  0.20446752, -0.24028288,\n",
       "                                  0.1068935 , -0.24332774,  0.11834247, -0.43644264,\n",
       "                                 -0.02317936, -0.38573587,  0.141738  ,  0.11776715,\n",
       "                                  0.4071066 , -0.89413506, -0.5232067 , -0.29121146,\n",
       "                                  0.1349041 , -0.14995281, -0.6072486 ,  0.31439045,\n",
       "                                 -0.24311817, -0.6128429 ,  0.61145765,  0.5701605 ,\n",
       "                                  0.2899103 , -0.34465683,  0.15892078,  0.17956081,\n",
       "                                 -0.07094992, -0.16064133,  0.00093165, -0.3747404 ,\n",
       "                                 -0.59049094,  0.05386654,  0.09549524, -0.04192615,\n",
       "                                 -0.41203362,  0.39526656, -0.19115703,  0.02204039,\n",
       "                                  0.18036191,  0.4340976 ,  0.38166875, -0.43801317,\n",
       "                                 -0.08310014, -0.59942114, -0.02029389,  0.42246008,\n",
       "                                 -0.6712887 ,  0.5309518 ,  0.39853522, -0.02946066,\n",
       "                                  0.06383175,  0.6732513 , -0.77791065, -0.51727635,\n",
       "                                 -0.1458139 ,  0.07193527,  0.53571177, -0.01303305,\n",
       "                                 -0.28793004, -0.06738477, -0.12830213, -0.37326616,\n",
       "                                  0.15805939,  0.15090224,  0.04478258,  0.17999738,\n",
       "                                  0.11032858,  0.47086287, -0.19285992,  0.19605467,\n",
       "                                 -0.584873  ,  0.45794243, -0.21445209,  0.12177301,\n",
       "                                  0.07795181,  0.7106062 , -0.12993781, -0.83605814,\n",
       "                                  0.31824136, -0.20917416,  0.4801406 , -0.26418087,\n",
       "                                  0.42210963,  0.05330511,  0.53055525,  0.39402267,\n",
       "                                  0.51239485, -0.31062964, -0.34040016, -0.31870538,\n",
       "                                 -0.22747229,  0.51606214,  0.6773921 , -0.07608554,\n",
       "                                  0.23270774, -0.44279748,  0.83892214, -0.21159568,\n",
       "                                  0.22313845, -0.37905392, -0.15945186, -0.47677845,\n",
       "                                 -0.48039487, -0.2134957 ,  0.36929458, -0.32304898,\n",
       "                                  0.19567995, -0.32010144,  0.5661126 ,  0.24182229,\n",
       "                                 -0.28352576,  0.2513959 , -0.13965459,  0.32292512,\n",
       "                                 -0.3752828 ,  0.07748513,  0.04970356, -0.4615164 ,\n",
       "                                 -0.08005196,  0.18632923,  0.49101862, -0.45114136,\n",
       "                                 -0.06659379, -0.11145493, -0.36507466,  0.5416089 ],\n",
       "                                [ 0.60341334,  0.54807794,  0.23180366,  0.62328976,\n",
       "                                  0.32160404, -0.21181643,  0.5066234 , -0.1764715 ,\n",
       "                                  0.05322418,  0.7904266 ,  0.6381001 ,  0.08143196,\n",
       "                                  0.2613095 , -0.13122085,  0.49332976,  0.02249951,\n",
       "                                 -0.23492363,  0.8051687 ,  0.148262  , -0.32874846,\n",
       "                                  0.02142128,  0.644865  ,  0.3188828 ,  0.67167264,\n",
       "                                  0.12084325, -0.23684146,  0.41772044, -0.08638532,\n",
       "                                 -0.11809759, -0.1398366 ,  0.5947752 , -0.36429426,\n",
       "                                  0.6448494 , -0.6640003 , -0.25098896,  0.0940865 ,\n",
       "                                  0.35626572, -0.26481265,  0.1552562 , -0.2295333 ,\n",
       "                                  0.4123814 , -0.51199746, -0.30370358, -0.25122204,\n",
       "                                  0.22412711, -0.65525705, -0.5189606 ,  0.26365426,\n",
       "                                  0.25816655,  0.37714654, -0.17065765, -0.7959    ,\n",
       "                                 -0.73116314,  0.06808047,  0.12245089, -0.5228395 ,\n",
       "                                  0.16296487,  0.70157725, -0.14686893, -0.73017806,\n",
       "                                 -0.6774403 ,  0.16441004, -0.24431425,  0.63759226,\n",
       "                                 -0.5120753 ,  0.33042026,  0.23029514,  0.02612291,\n",
       "                                 -0.17629129, -0.31674618, -0.01743083, -0.7853514 ,\n",
       "                                 -0.299166  , -0.41703054,  0.05038549,  0.18189627,\n",
       "                                 -0.6097083 ,  0.24561496, -0.64955467, -0.14777872,\n",
       "                                 -0.04454107, -0.06146859,  0.02962237, -0.28424317,\n",
       "                                 -0.17867616,  0.73606664,  0.44126096,  0.40669388,\n",
       "                                  0.46346095, -0.2960111 , -0.10774878,  0.122811  ,\n",
       "                                 -0.4233559 ,  0.4928587 , -0.29534367, -0.26544288,\n",
       "                                 -0.65012836, -0.62335926,  0.14083806,  0.52095765,\n",
       "                                  0.16673817, -0.17665944,  0.28258198,  0.46835947,\n",
       "                                 -0.7339206 ,  0.14724953, -0.46980578,  0.3892157 ,\n",
       "                                 -0.65586555, -0.71032244, -0.32661018,  0.24843907,\n",
       "                                 -0.78327507, -0.19571812,  0.32554993, -0.18159315,\n",
       "                                  0.23352088,  0.26966536, -0.08809161, -0.6391998 ,\n",
       "                                 -0.25095776,  0.13118088,  0.41116688, -0.154836  ,\n",
       "                                 -0.3517275 ,  0.14274135,  0.33390108,  0.02078804],\n",
       "                                [-0.5625415 , -0.32782063,  0.48920187, -0.17957145,\n",
       "                                  0.73247164,  0.1165147 ,  0.43928328,  0.15324794,\n",
       "                                  0.12836608, -0.6569364 , -0.18435419,  0.47462067,\n",
       "                                  0.06875452, -0.3478043 , -0.04289135,  0.04273745,\n",
       "                                  0.57948613,  0.2460976 ,  0.4627468 , -0.6136611 ,\n",
       "                                 -0.05437664,  0.4459972 , -0.00510083,  0.12645867,\n",
       "                                  0.3111619 , -0.16328889, -0.2337573 , -0.5333843 ,\n",
       "                                 -0.0900099 ,  0.46972892,  0.37037316, -0.2335105 ,\n",
       "                                 -0.6355765 , -0.5313621 ,  0.25871325,  0.538969  ,\n",
       "                                  0.17187458, -0.061611  , -0.21564928, -0.6806424 ,\n",
       "                                 -0.33282936,  0.14898221, -0.17492718, -0.01723464,\n",
       "                                 -0.25002944,  0.10861695,  0.62354994, -0.40684363,\n",
       "                                 -0.02955513,  0.49702695,  0.12199475,  0.6352674 ,\n",
       "                                  0.11270073, -0.3481952 , -0.38995764,  0.4460979 ,\n",
       "                                 -0.46905833,  0.21841381,  0.0369926 , -0.3718445 ,\n",
       "                                  0.26910794,  0.28506428,  0.16280717,  0.21256043,\n",
       "                                  0.34318307, -0.35736242, -0.06274372, -0.26766977,\n",
       "                                 -0.00400598,  0.48653463,  0.09260507, -0.72637564,\n",
       "                                 -0.33795744, -0.83087176,  0.22840475,  0.04460067,\n",
       "                                  0.2509143 , -0.14373691,  0.11579686,  0.3760107 ,\n",
       "                                  0.8719564 ,  0.43819198,  0.43945834,  0.120519  ,\n",
       "                                  0.27288043, -0.01677129, -0.421952  , -0.06338387,\n",
       "                                 -0.21110436,  0.66737   ,  0.7698889 , -0.13149399,\n",
       "                                  0.04660459,  0.7790231 , -0.45137203, -0.17817478,\n",
       "                                  0.5171412 , -0.63851905, -0.26055413, -0.2330522 ,\n",
       "                                 -0.66624576,  0.12637863,  0.22995557,  0.47285223,\n",
       "                                 -0.23091558,  0.43007997,  0.81916916,  0.21346425,\n",
       "                                  0.21980181,  0.79349506, -0.86626494, -0.04862151,\n",
       "                                 -0.50740075,  0.10772226,  0.25222173,  0.23544316,\n",
       "                                  0.18192202,  0.45817417,  0.14662969,  0.33069852,\n",
       "                                 -0.7523784 ,  0.3507269 ,  0.09762207, -0.29326227,\n",
       "                                 -0.32515723,  0.25088522,  0.3257664 , -0.63306457],\n",
       "                                [ 0.46510094,  0.41220716,  0.05147239, -0.25600055,\n",
       "                                  0.40837765,  0.4820097 , -0.59197086, -0.6216788 ,\n",
       "                                 -0.63674927, -0.5700651 ,  0.6954295 ,  0.4273683 ,\n",
       "                                  0.24084286, -0.5581854 ,  0.10960761,  0.6913509 ,\n",
       "                                  0.5488517 ,  0.37757233, -0.6021056 ,  0.11661722,\n",
       "                                  0.1404616 , -0.6220772 , -0.08503768,  0.23560786,\n",
       "                                  0.16242313, -0.36027005,  0.18170938, -0.28451437,\n",
       "                                 -0.23183005,  0.01119663, -0.29498953, -0.71703553,\n",
       "                                  0.07029124,  0.00327125, -0.1954899 , -0.5570367 ,\n",
       "                                  0.32429335,  0.44391882,  0.44995654, -0.06932778,\n",
       "                                 -0.21918459, -0.09869797,  0.7034007 , -0.30790868,\n",
       "                                  0.09252309, -0.6397253 , -0.48585775, -0.46740454,\n",
       "                                 -0.3371397 ,  0.35892016,  0.39371884, -0.16333812,\n",
       "                                  0.35192683, -0.51915914,  0.2287661 , -0.5759151 ,\n",
       "                                 -0.11435948,  0.16746333,  0.46464053, -0.49380535,\n",
       "                                  0.6987533 ,  0.3184856 ,  0.16913626,  0.33750635,\n",
       "                                  0.01092498,  0.55375254,  0.275675  , -0.29405504,\n",
       "                                 -0.3055652 ,  0.42555648,  0.4594912 , -0.34432435,\n",
       "                                  0.00932531,  0.33397427, -0.20687653,  0.3607177 ,\n",
       "                                 -0.06124686,  0.24511869,  0.31805262,  0.52568513,\n",
       "                                 -0.05807637,  0.4760305 ,  0.21934654, -0.37652114,\n",
       "                                 -0.39759526,  0.38683274, -0.55764264, -0.18656395,\n",
       "                                 -0.8829222 ,  0.39901987, -0.05169531, -0.6320234 ,\n",
       "                                 -0.39582482, -0.19420321,  0.71706045,  0.00985516,\n",
       "                                 -0.1919749 ,  0.14418827,  0.80004996,  0.83631605,\n",
       "                                 -0.3629556 , -0.08878463,  0.34835804,  0.00734573,\n",
       "                                 -0.7434061 ,  0.13929263, -0.13138251,  0.44343457,\n",
       "                                  0.5394721 ,  0.21304025,  0.6567282 ,  0.42790684,\n",
       "                                  0.49044397, -0.3638781 ,  0.44077376,  0.6389545 ,\n",
       "                                 -0.08389826,  0.21384643,  0.10055289, -0.40805742,\n",
       "                                  0.2648482 ,  0.05158834,  0.31803256, -0.05751133,\n",
       "                                  0.43372643,  0.0603372 , -0.29659534,  0.11028651],\n",
       "                                [ 0.22320202,  0.1672889 , -0.3322564 ,  0.5392972 ,\n",
       "                                 -0.32724038, -0.35965568, -0.08001139,  0.06214724,\n",
       "                                 -0.47241968,  0.47297925, -0.07321104, -0.45477983,\n",
       "                                  0.24831185, -0.16104315, -0.02174105,  0.36188093,\n",
       "                                 -0.01539244, -0.09330042,  0.40728676, -0.49500057,\n",
       "                                 -0.42585704,  0.11823653, -0.15218167, -0.25678167,\n",
       "                                  0.1827914 ,  0.0640592 , -0.210446  ,  0.7357628 ,\n",
       "                                 -0.09611335,  0.8308931 ,  0.16751245, -0.34537444,\n",
       "                                 -0.05380037, -0.19432463, -0.05169736,  0.63325256,\n",
       "                                 -0.39671654, -0.04193923,  0.08777118, -0.4223455 ,\n",
       "                                  0.4253493 ,  0.01014771,  0.11323814, -0.17801903,\n",
       "                                  0.43915272,  0.64005226,  0.24072257, -0.28322002,\n",
       "                                  0.42415696, -0.16098098, -0.76435965, -0.49615428,\n",
       "                                 -0.4155184 , -0.3145741 ,  0.10054294, -0.36724678,\n",
       "                                  0.34445447,  0.00238462,  0.3326761 , -0.12209298,\n",
       "                                  0.7148469 ,  0.29469028, -0.13670027,  0.39482826,\n",
       "                                  0.06729756,  0.24549454, -0.8338992 , -0.87577486,\n",
       "                                  0.29362375, -0.25308892,  0.16904885, -0.47224417,\n",
       "                                  0.4358713 , -0.10889731,  0.15529643,  0.43758765,\n",
       "                                 -0.40369976,  0.1716981 ,  0.32973343, -0.8503975 ,\n",
       "                                  0.30779672,  0.1422275 , -0.09385973,  0.07037117,\n",
       "                                 -0.07170592,  0.01101187,  0.4415873 ,  0.28535408,\n",
       "                                 -0.7441609 ,  0.663508  , -0.49032855,  0.3470852 ,\n",
       "                                 -0.05287812, -0.01986718, -0.31244552, -0.11440982,\n",
       "                                  0.06820305, -0.17589395,  0.15829419,  0.18607426,\n",
       "                                  0.27912465,  0.5144001 ,  0.05148844, -0.4581183 ,\n",
       "                                 -0.29964575,  0.12580392,  0.09095235,  0.6266663 ,\n",
       "                                  0.85644376, -0.06336635, -0.13969597,  0.38661972,\n",
       "                                  0.20233542, -0.4964619 , -0.8580205 ,  0.22638652,\n",
       "                                  0.27696067,  0.78397393, -0.2895555 ,  0.56312215,\n",
       "                                  0.07762627, -0.12127709, -0.74777234, -0.19206148,\n",
       "                                  0.7835999 ,  0.20030896, -0.04833552, -0.1471181 ]],            dtype=float32),\n",
       "              'b': DeviceArray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                                0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                                0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                                0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                                0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                                0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                                0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                                0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                                0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       "            }),\n",
       "  'linear_1': FlatMap({\n",
       "                'w': DeviceArray([[-0.12587442,  0.09692949, -0.01006178, ..., -0.01565989,\n",
       "                                   -0.05695537, -0.01284519],\n",
       "                                  [-0.11377474, -0.07467062, -0.04383816, ..., -0.09292383,\n",
       "                                   -0.03761953,  0.01124866],\n",
       "                                  [ 0.12630013,  0.0024494 , -0.08546209, ..., -0.02559158,\n",
       "                                    0.00252438, -0.03643405],\n",
       "                                  ...,\n",
       "                                  [-0.04887566, -0.03295173,  0.11174479, ..., -0.0557049 ,\n",
       "                                   -0.04089615, -0.07976684],\n",
       "                                  [ 0.00822432, -0.0523496 , -0.09676804, ..., -0.12625843,\n",
       "                                    0.14008087,  0.1495473 ],\n",
       "                                  [-0.07839397,  0.12946756,  0.10921853, ...,  0.01625304,\n",
       "                                    0.08023666,  0.04043131]], dtype=float32),\n",
       "                'b': DeviceArray([0., 0., 0., ..., 0., 0., 0.], dtype=float32),\n",
       "              }),\n",
       "  'linear_2': FlatMap({\n",
       "                'w': DeviceArray([[ 0.01662212, -0.0257397 , -0.05794957, ..., -0.00563361,\n",
       "                                    0.05855527, -0.00361029],\n",
       "                                  [-0.05795113, -0.01663478,  0.01183455, ..., -0.03193253,\n",
       "                                    0.02164118, -0.02380082],\n",
       "                                  [-0.00516822, -0.01162354, -0.01463831, ..., -0.00829154,\n",
       "                                   -0.03146287,  0.01494288],\n",
       "                                  ...,\n",
       "                                  [-0.01310027,  0.00421011, -0.05075891, ..., -0.01488484,\n",
       "                                   -0.04915964, -0.04000212],\n",
       "                                  [-0.05181462, -0.01746036, -0.00833169, ...,  0.05391343,\n",
       "                                   -0.02435188,  0.01323952],\n",
       "                                  [ 0.02027034, -0.01701951,  0.02167752, ..., -0.01265488,\n",
       "                                   -0.0349408 , -0.00464169]], dtype=float32),\n",
       "                'b': DeviceArray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                                  0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                                  0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                                  0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                                  0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                                  0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                                  0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                                  0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                                  0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       "              }),\n",
       "  'linear_3': FlatMap({\n",
       "                'w': DeviceArray([[-0.03661142, -0.07761122,  0.08147847, ..., -0.15130323,\n",
       "                                   -0.02045452,  0.01981121],\n",
       "                                  [-0.07366855,  0.06043554,  0.10474381, ...,  0.03899808,\n",
       "                                   -0.0140873 ,  0.07735711],\n",
       "                                  [-0.02971755, -0.0666496 ,  0.07300878, ..., -0.05298653,\n",
       "                                    0.12991636,  0.01982105],\n",
       "                                  ...,\n",
       "                                  [-0.03670288, -0.0176894 , -0.11497618, ..., -0.09709148,\n",
       "                                   -0.13436408, -0.09354488],\n",
       "                                  [ 0.02007937, -0.038489  , -0.04631043, ...,  0.08798911,\n",
       "                                    0.1019537 ,  0.06113573],\n",
       "                                  [-0.03514194,  0.023434  ,  0.15555467, ..., -0.12772138,\n",
       "                                   -0.08131336, -0.02278348]], dtype=float32),\n",
       "                'b': DeviceArray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                                  0.], dtype=float32),\n",
       "              }),\n",
       "  'linear_4': FlatMap({\n",
       "                'w': DeviceArray([[ 0.03984209],\n",
       "                                  [-0.01006918],\n",
       "                                  [ 0.38232717],\n",
       "                                  [-0.19959453],\n",
       "                                  [-0.23299852],\n",
       "                                  [-0.35636207],\n",
       "                                  [-0.22952425],\n",
       "                                  [-0.38133147],\n",
       "                                  [-0.28719792],\n",
       "                                  [ 0.13899693],\n",
       "                                  [ 0.04617171],\n",
       "                                  [ 0.25584504],\n",
       "                                  [-0.15277824],\n",
       "                                  [-0.44226837],\n",
       "                                  [ 0.00320479],\n",
       "                                  [ 0.4415688 ]], dtype=float32),\n",
       "                'b': DeviceArray([0.], dtype=float32),\n",
       "              }),\n",
       "})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n",
      "Epoch 0 in 16.46 sec\n",
      "Epoch 1 in 14.94 sec\n",
      "Epoch 2 in 15.24 sec\n",
      "Epoch 3 in 14.88 sec\n",
      "Epoch 4 in 15.07 sec\n",
      "Epoch 5 in 14.97 sec\n",
      "Epoch 6 in 15.25 sec\n",
      "Epoch 7 in 15.08 sec\n",
      "Epoch 8 in 15.19 sec\n",
      "Epoch 9 in 15.77 sec\n",
      "Epoch 10 in 15.03 sec\n",
      "Epoch 11 in 15.02 sec\n",
      "Epoch 12 in 15.28 sec\n",
      "Epoch 13 in 15.24 sec\n",
      "Epoch 14 in 16.27 sec\n",
      "Epoch 15 in 15.38 sec\n",
      "Epoch 16 in 15.15 sec\n",
      "Epoch 17 in 16.95 sec\n",
      "Epoch 18 in 16.84 sec\n",
      "Epoch 19 in 15.16 sec\n",
      "Epoch 20 in 15.16 sec\n",
      "Epoch 21 in 15.42 sec\n",
      "Epoch 22 in 15.28 sec\n",
      "Epoch 23 in 15.76 sec\n",
      "Epoch 24 in 15.63 sec\n",
      "Epoch 25 in 16.22 sec\n",
      "Epoch 26 in 15.68 sec\n",
      "Epoch 27 in 15.24 sec\n",
      "Epoch 28 in 15.27 sec\n",
      "Epoch 29 in 15.26 sec\n",
      "Epoch 30 in 15.21 sec\n",
      "Epoch 31 in 15.23 sec\n",
      "Epoch 32 in 15.26 sec\n",
      "Epoch 33 in 15.25 sec\n",
      "Epoch 34 in 15.04 sec\n",
      "Epoch 35 in 15.14 sec\n",
      "Epoch 36 in 15.06 sec\n",
      "Epoch 37 in 15.22 sec\n",
      "Epoch 38 in 15.52 sec\n",
      "Epoch 39 in 15.25 sec\n",
      "Epoch 40 in 15.14 sec\n",
      "Epoch 41 in 15.27 sec\n",
      "Epoch 42 in 15.14 sec\n",
      "Epoch 43 in 15.17 sec\n",
      "Epoch 44 in 15.22 sec\n",
      "Epoch 45 in 15.18 sec\n",
      "Epoch 46 in 15.18 sec\n",
      "Epoch 47 in 15.18 sec\n",
      "Epoch 48 in 14.95 sec\n",
      "Epoch 49 in 15.11 sec\n",
      "Epoch 50 in 14.93 sec\n",
      "Epoch 51 in 15.09 sec\n",
      "Epoch 52 in 15.00 sec\n",
      "Epoch 53 in 15.05 sec\n",
      "Epoch 54 in 15.09 sec\n",
      "Epoch 55 in 15.00 sec\n",
      "Epoch 56 in 15.03 sec\n",
      "Epoch 57 in 15.09 sec\n",
      "Epoch 58 in 15.06 sec\n",
      "Epoch 59 in 14.99 sec\n",
      "Epoch 60 in 15.21 sec\n",
      "Epoch 61 in 15.30 sec\n",
      "Epoch 62 in 15.10 sec\n",
      "Epoch 63 in 15.20 sec\n",
      "Epoch 64 in 15.08 sec\n",
      "Epoch 65 in 15.27 sec\n",
      "Epoch 66 in 15.11 sec\n",
      "Epoch 67 in 15.16 sec\n",
      "Epoch 68 in 15.25 sec\n",
      "Epoch 69 in 15.14 sec\n",
      "Epoch 70 in 15.13 sec\n",
      "Epoch 71 in 14.98 sec\n",
      "Epoch 72 in 15.04 sec\n",
      "Epoch 73 in 14.97 sec\n",
      "Epoch 74 in 16.73 sec\n",
      "Epoch 75 in 17.45 sec\n",
      "Epoch 76 in 17.32 sec\n",
      "Epoch 77 in 18.65 sec\n",
      "Epoch 78 in 22.34 sec\n",
      "Epoch 79 in 25.04 sec\n"
     ]
    }
   ],
   "source": [
    "def sgd(param, update):\n",
    "    return param - step_size * update\n",
    "\n",
    "print(\"\\nStarting training...\")\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    for _ in range(num_batches):\n",
    "        x_iter, y_iter = next(batches)\n",
    "        grads = jax.grad(loss_fn_t.apply)(params, x_iter, y_iter)\n",
    "        params = jax.tree_multimap(sgd, params, grads)\n",
    "    epoch_time = time.time() - start_time    \n",
    "    #train_acc = accuracy(params, x.values, y.values)\n",
    "    print(\"Epoch {} in {:0.2f} sec\".format(epoch, epoch_time))\n",
    "    #print(\"Training set accuracy {}\".format(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(nan, dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn_t.apply(params,x.values,y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FlatMap({\n",
       "  'linear': FlatMap({\n",
       "              'b': DeviceArray([         nan,          nan, -397.1789   ,  -97.34782  ,\n",
       "                                -297.47705  ,          nan, -465.82858  ,    0.       ,\n",
       "                                   0.       , -131.5717   , -336.90704  ,          nan,\n",
       "                                -216.40575  ,    0.       ,          nan,          nan,\n",
       "                                -447.69424  ,          nan,    0.       ,          nan,\n",
       "                                  -6.2996573,          nan,          nan, -155.28235  ,\n",
       "                                         nan,    0.       , -141.9651   ,          nan,\n",
       "                                   0.       ,          nan,  -15.818071 ,    0.       ,\n",
       "                                         nan,    0.       ,    0.       ,  -53.556313 ,\n",
       "                                         nan, -231.59782  ,          nan,    0.       ,\n",
       "                                         nan,  -27.464762 , -154.47498  ,    0.       ,\n",
       "                                         nan,    0.       ,    0.       ,          nan,\n",
       "                                   0.       , -479.353    ,          nan,    0.       ,\n",
       "                                         nan,          nan,    0.       ,    0.       ,\n",
       "                                 -56.11891  ,          nan, -674.8876   ,    0.       ,\n",
       "                                 -50.4571   ,          nan,  -33.39615  , -210.71687  ,\n",
       "                                  -1.727012 , -301.083    , -198.74434  , -154.79825  ,\n",
       "                                   0.       , -796.9721   ,          nan,    0.       ,\n",
       "                                   0.       ,          nan,          nan,          nan,\n",
       "                                   0.       , -108.17392  ,          nan,  -25.646696 ,\n",
       "                                -559.7245   ,          nan, -513.48096  ,    0.       ,\n",
       "                                 -81.76485  ,          nan, -648.8813   ,          nan,\n",
       "                                 -67.50488  ,  -37.79761  ,    0.       ,    0.       ,\n",
       "                                   0.       ,          nan,          nan,    0.       ,\n",
       "                                   0.       ,    0.       ,  -29.08423  ,  -47.662502 ,\n",
       "                                         nan,    0.       , -158.25653  , -290.49878  ,\n",
       "                                   0.       ,          nan,          nan, -364.24887  ,\n",
       "                                         nan,          nan,          nan,          nan,\n",
       "                                  -1.9642684,  -49.25405  , -508.0348   , -573.82996  ,\n",
       "                                         nan,          nan, -176.17242  ,    0.       ,\n",
       "                                 -35.360172 ,          nan,  -76.9311   ,    0.       ,\n",
       "                                 -71.55628  ,          nan,  -70.41916  , -164.48094  ],            dtype=float32),\n",
       "              'w': DeviceArray([[            nan,             nan, -4.81051025e+02,\n",
       "                                 -1.31649643e+02, -3.50705444e+02,             nan,\n",
       "                                 -5.54344360e+02, -4.36442643e-01, -2.31793616e-02,\n",
       "                                 -1.58259186e+02, -4.19158722e+02,             nan,\n",
       "                                 -2.46901962e+02, -8.94135058e-01,             nan,\n",
       "                                             nan, -5.78702087e+02,             nan,\n",
       "                                 -6.07248604e-01,             nan, -5.76159525e+00,\n",
       "                                             nan,             nan, -2.28898438e+02,\n",
       "                                             nan, -3.44656825e-01, -1.55500473e+02,\n",
       "                                             nan, -7.09499195e-02,             nan,\n",
       "                                 -8.15150738e+00, -3.74740392e-01,             nan,\n",
       "                                  5.38665354e-02,  9.54952389e-02, -7.10221558e+01,\n",
       "                                             nan, -2.99500824e+02,             nan,\n",
       "                                  2.20403895e-02,             nan, -4.52779655e+01,\n",
       "                                 -2.09374252e+02, -4.38013166e-01,             nan,\n",
       "                                 -5.99421144e-01, -2.02938896e-02,             nan,\n",
       "                                 -6.71288729e-01, -5.33846313e+02,             nan,\n",
       "                                 -2.94606593e-02,             nan,             nan,\n",
       "                                 -7.77910650e-01, -5.17276347e-01, -6.48284531e+01,\n",
       "                                             nan, -8.08673462e+02, -1.30330455e-02,\n",
       "                                 -5.11608047e+01,             nan, -3.23256607e+01,\n",
       "                                 -2.90399017e+02, -2.86555219e+00, -3.76789978e+02,\n",
       "                                 -2.50975677e+02, -2.08335907e+02,  1.10328577e-01,\n",
       "                                 -9.71716675e+02,             nan,  1.96054667e-01,\n",
       "                                 -5.84873021e-01,             nan,             nan,\n",
       "                                             nan,  7.79518113e-02, -1.10041313e+02,\n",
       "                                             nan, -2.30554028e+01, -7.40382202e+02,\n",
       "                                             nan, -5.58314941e+02, -2.64180869e-01,\n",
       "                                 -1.20234673e+02,             nan, -8.18856384e+02,\n",
       "                                             nan, -1.24021759e+02, -3.84285812e+01,\n",
       "                                 -3.40400159e-01, -3.18705380e-01, -2.27472290e-01,\n",
       "                                             nan,             nan, -7.60855377e-02,\n",
       "                                  2.32707739e-01, -4.42797482e-01, -4.21340752e+01,\n",
       "                                 -7.88959885e+01,             nan, -3.79053921e-01,\n",
       "                                 -2.17748047e+02, -3.27363739e+02, -4.80394870e-01,\n",
       "                                             nan,             nan, -4.29820862e+02,\n",
       "                                             nan,             nan,             nan,\n",
       "                                             nan, -2.34861588e+00, -9.33652420e+01,\n",
       "                                 -5.76118713e+02, -7.42541687e+02,             nan,\n",
       "                                             nan, -2.02958328e+02, -4.61516410e-01,\n",
       "                                 -3.93186646e+01,             nan, -8.55789871e+01,\n",
       "                                 -4.51141357e-01, -9.76270905e+01,             nan,\n",
       "                                 -7.70987396e+01, -1.89407761e+02],\n",
       "                                [            nan,             nan, -4.89501282e+02,\n",
       "                                 -1.26954109e+02, -3.87580627e+02,             nan,\n",
       "                                 -5.57769409e+02, -1.76471502e-01,  5.32241836e-02,\n",
       "                                 -2.10785400e+02, -4.12972504e+02,             nan,\n",
       "                                 -2.75160706e+02, -1.31220847e-01,             nan,\n",
       "                                             nan, -5.49098022e+02,             nan,\n",
       "                                  1.48261994e-01,             nan, -4.54430199e+00,\n",
       "                                             nan,             nan, -1.99592056e+02,\n",
       "                                             nan, -2.36841455e-01, -1.59408096e+02,\n",
       "                                             nan, -1.18097588e-01,             nan,\n",
       "                                 -7.68882599e+01, -3.64294261e-01,             nan,\n",
       "                                 -6.64000273e-01, -2.50988960e-01, -9.72282867e+01,\n",
       "                                             nan, -2.96519806e+02,             nan,\n",
       "                                 -2.29533300e-01,             nan, -2.59789944e+01,\n",
       "                                 -1.79164352e+02, -2.51222044e-01,             nan,\n",
       "                                 -6.55257046e-01, -5.18960595e-01,             nan,\n",
       "                                  2.58166552e-01, -6.07057739e+02,             nan,\n",
       "                                 -7.95899987e-01,             nan,             nan,\n",
       "                                  1.22450888e-01, -5.22839487e-01, -1.09036209e+02,\n",
       "                                             nan, -8.74297302e+02, -7.30178058e-01,\n",
       "                                 -4.02350655e+01,             nan, -2.44910851e+01,\n",
       "                                 -2.46734711e+02, -1.67847121e+00, -3.71198364e+02,\n",
       "                                 -1.69201355e+02, -2.54458023e+02, -1.76291287e-01,\n",
       "                                 -9.51537964e+02,             nan, -7.85351396e-01,\n",
       "                                 -2.99165994e-01,             nan,             nan,\n",
       "                                             nan, -6.09708309e-01, -1.02167244e+02,\n",
       "                                             nan, -1.89853001e+01, -6.78908752e+02,\n",
       "                                             nan, -5.55816956e+02, -2.84243166e-01,\n",
       "                                 -1.15661530e+02,             nan, -8.85620300e+02,\n",
       "                                             nan, -1.06965775e+02, -3.32934608e+01,\n",
       "                                 -1.07748777e-01,  1.22810997e-01, -4.23355907e-01,\n",
       "                                             nan,             nan, -2.65442878e-01,\n",
       "                                 -6.50128365e-01, -6.23359263e-01,  3.34354901e+00,\n",
       "                                 -1.30499908e+02,             nan, -1.76659435e-01,\n",
       "                                 -1.81040283e+02, -4.02661926e+02, -7.33920574e-01,\n",
       "                                             nan,             nan, -4.33714020e+02,\n",
       "                                             nan,             nan,             nan,\n",
       "                                             nan, -2.17222238e+00, -7.56184921e+01,\n",
       "                                 -6.71979980e+02, -7.35151550e+02,             nan,\n",
       "                                             nan, -2.07681595e+02, -6.39199793e-01,\n",
       "                                 -2.62312965e+01,             nan, -1.50594772e+02,\n",
       "                                 -1.54835999e-01, -5.96640701e+01,             nan,\n",
       "                                 -1.22462700e+02, -1.99708755e+02],\n",
       "                                [            nan,             nan, -9.63366547e+01,\n",
       "                                 -1.92621307e+01, -7.21238098e+01,             nan,\n",
       "                                 -1.14212402e+02,  1.53247938e-01,  1.28366083e-01,\n",
       "                                 -3.12789917e+01, -8.23164062e+01,             nan,\n",
       "                                 -5.49520226e+01, -3.47804308e-01,             nan,\n",
       "                                             nan, -1.13482475e+02,             nan,\n",
       "                                  4.62746799e-01,             nan, -1.67964280e+00,\n",
       "                                             nan,             nan, -3.52777214e+01,\n",
       "                                             nan, -1.63288891e-01, -3.36960144e+01,\n",
       "                                             nan, -9.00098979e-02,             nan,\n",
       "                                 -8.61369610e+00, -2.33510494e-01,             nan,\n",
       "                                 -5.31362116e-01,  2.58713245e-01, -1.38801279e+01,\n",
       "                                             nan, -6.09550591e+01,             nan,\n",
       "                                 -6.80642426e-01,             nan, -7.57224751e+00,\n",
       "                                 -3.77827492e+01, -1.72346421e-02,             nan,\n",
       "                                  1.08616948e-01,  6.23549938e-01,             nan,\n",
       "                                 -2.95551307e-02, -1.17348434e+02,             nan,\n",
       "                                  6.35267377e-01,             nan,             nan,\n",
       "                                 -3.89957637e-01,  4.46097910e-01, -1.11965590e+01,\n",
       "                                             nan, -1.63930252e+02, -3.71844500e-01,\n",
       "                                 -1.11837139e+01,             nan, -8.39819813e+00,\n",
       "                                 -5.12069893e+01, -2.85200387e-01, -7.12207108e+01,\n",
       "                                 -4.79975739e+01, -3.73195686e+01, -4.00598394e-03,\n",
       "                                 -1.97591019e+02,             nan, -7.26375639e-01,\n",
       "                                 -3.37957442e-01,             nan,             nan,\n",
       "                                             nan,  2.50914305e-01, -2.48476791e+01,\n",
       "                                             nan, -5.94313955e+00, -1.39126312e+02,\n",
       "                                             nan, -1.27428276e+02,  1.20519005e-01,\n",
       "                                 -2.18034821e+01,             nan, -1.54549377e+02,\n",
       "                                             nan, -1.24454498e+01, -8.97874737e+00,\n",
       "                                  7.69888878e-01, -1.31493986e-01,  4.66045924e-02,\n",
       "                                             nan,             nan, -1.78174779e-01,\n",
       "                                  5.17141223e-01, -6.38519049e-01, -2.06285763e+00,\n",
       "                                 -8.68196106e+00,             nan,  1.26378626e-01,\n",
       "                                 -3.72236710e+01, -6.99478683e+01, -2.30915576e-01,\n",
       "                                             nan,             nan, -8.58609085e+01,\n",
       "                                             nan,             nan,             nan,\n",
       "                                             nan, -8.45200062e-01, -1.24751730e+01,\n",
       "                                 -1.22744377e+02, -1.40266159e+02,             nan,\n",
       "                                             nan, -4.34893684e+01,  3.30698520e-01,\n",
       "                                 -7.87548304e+00,             nan, -2.09906368e+01,\n",
       "                                 -2.93262273e-01, -1.71274681e+01,             nan,\n",
       "                                 -1.58379011e+01, -4.00058250e+01],\n",
       "                                [            nan,             nan, -3.44233704e+02,\n",
       "                                 -6.90075989e+01, -2.34372620e+02,             nan,\n",
       "                                 -3.65089722e+02, -6.21678829e-01, -6.36749268e-01,\n",
       "                                 -5.53654251e+01, -2.89308044e+02,             nan,\n",
       "                                 -1.74907913e+02, -5.58185399e-01,             nan,\n",
       "                                             nan, -3.37323120e+02,             nan,\n",
       "                                 -6.02105618e-01,             nan, -1.19096680e+01,\n",
       "                                             nan,             nan, -1.07641449e+02,\n",
       "                                             nan, -3.60270053e-01, -1.47595398e+02,\n",
       "                                             nan, -2.31830046e-01,             nan,\n",
       "                                  3.78406639e+01, -7.17035532e-01,             nan,\n",
       "                                  3.27125448e-03, -1.95489898e-01, -1.74025650e+01,\n",
       "                                             nan, -1.54627991e+02,             nan,\n",
       "                                 -6.93277791e-02,             nan, -3.68143349e+01,\n",
       "                                 -1.40083679e+02, -3.07908684e-01,             nan,\n",
       "                                 -6.39725327e-01, -4.85857755e-01,             nan,\n",
       "                                 -3.37139696e-01, -3.69228729e+02,             nan,\n",
       "                                 -1.63338125e-01,             nan,             nan,\n",
       "                                  2.28766099e-01, -5.75915098e-01, -1.53663721e+01,\n",
       "                                             nan, -5.17005554e+02, -4.93805349e-01,\n",
       "                                 -8.31550674e+01,             nan, -6.35010757e+01,\n",
       "                                 -1.92271088e+02, -3.65516829e+00, -2.57381165e+02,\n",
       "                                 -2.62373718e+02, -6.32220650e+01, -3.05565208e-01,\n",
       "                                 -7.09462524e+02,             nan, -3.44324350e-01,\n",
       "                                  9.32531338e-03,             nan,             nan,\n",
       "                                             nan, -6.12468608e-02, -1.30020767e+02,\n",
       "                                             nan, -4.72977257e+01, -4.83753510e+02,\n",
       "                                             nan, -5.03937927e+02, -3.76521140e-01,\n",
       "                                 -5.07934875e+01,             nan, -4.15333130e+02,\n",
       "                                             nan, -3.67449226e+01, -5.36908951e+01,\n",
       "                                 -5.16953059e-02, -6.32023394e-01, -3.95824820e-01,\n",
       "                                             nan,             nan,  9.85516235e-03,\n",
       "                                 -1.91974893e-01,  1.44188270e-01, -5.39981804e+01,\n",
       "                                  6.73503952e+01,             nan, -8.87846276e-02,\n",
       "                                 -1.43347794e+02, -1.81847198e+02, -7.43406117e-01,\n",
       "                                             nan,             nan, -3.05630859e+02,\n",
       "                                             nan,             nan,             nan,\n",
       "                                             nan, -3.43809295e+00, -2.30082531e+01,\n",
       "                                 -3.75293365e+02, -4.47141388e+02,             nan,\n",
       "                                             nan, -1.26118004e+02, -4.08057421e-01,\n",
       "                                 -6.56304703e+01,             nan,  2.58536663e+01,\n",
       "                                 -5.75113297e-02, -1.05328896e+02,             nan,\n",
       "                                 -2.51796341e+01, -1.73185684e+02],\n",
       "                                [            nan,             nan, -5.79120636e+00,\n",
       "                                 -1.00785172e+00, -4.14287090e+00,             nan,\n",
       "                                 -6.87453556e+00,  6.21472411e-02, -4.72419679e-01,\n",
       "                                 -1.18334270e+00, -4.58734798e+00,             nan,\n",
       "                                 -2.71648788e+00, -1.61043152e-01,             nan,\n",
       "                                             nan, -6.52629757e+00,             nan,\n",
       "                                  4.07286763e-01,             nan, -5.03531575e-01,\n",
       "                                             nan,             nan, -2.72340298e+00,\n",
       "                                             nan,  6.40591979e-02, -2.19965601e+00,\n",
       "                                             nan, -9.61133465e-02,             nan,\n",
       "                                  1.49671644e-01, -3.45374435e-01,             nan,\n",
       "                                 -1.94324628e-01, -5.16973622e-02, -1.90093338e-01,\n",
       "                                             nan, -3.37633634e+00,             nan,\n",
       "                                 -4.22345489e-01,             nan, -3.77621353e-01,\n",
       "                                 -2.04787159e+00, -1.78019032e-01,             nan,\n",
       "                                  6.40052259e-01,  2.40722567e-01,             nan,\n",
       "                                  4.24156964e-01, -6.75135612e+00,             nan,\n",
       "                                 -4.96154279e-01,             nan,             nan,\n",
       "                                  1.00542940e-01, -3.67246777e-01, -3.33227277e-01,\n",
       "                                             nan, -8.83047009e+00, -1.22092977e-01,\n",
       "                                  4.07494903e-02,             nan, -5.66004395e-01,\n",
       "                                 -2.80060530e+00,  4.75945510e-02, -4.06846714e+00,\n",
       "                                 -3.75974989e+00, -2.97287083e+00,  2.93623745e-01,\n",
       "                                 -1.14362106e+01,             nan, -4.72244173e-01,\n",
       "                                  4.35871303e-01,             nan,             nan,\n",
       "                                             nan, -4.03699756e-01, -1.31067359e+00,\n",
       "                                             nan, -1.19811416e+00, -7.43438244e+00,\n",
       "                                             nan, -7.28542280e+00,  7.03711733e-02,\n",
       "                                 -1.29505360e+00,             nan, -8.52235603e+00,\n",
       "                                             nan, -1.75386977e+00,  5.65305352e-02,\n",
       "                                 -4.90328550e-01,  3.47085208e-01, -5.28781228e-02,\n",
       "                                             nan,             nan, -1.14409819e-01,\n",
       "                                  6.82030544e-02, -1.75893947e-01, -2.99465537e-01,\n",
       "                                 -4.38504636e-01,             nan,  5.14400125e-01,\n",
       "                                 -2.32196188e+00, -4.43342590e+00, -2.99645752e-01,\n",
       "                                             nan,             nan, -4.46044445e+00,\n",
       "                                             nan,             nan,             nan,\n",
       "                                             nan,  1.71562508e-01, -1.23541415e+00,\n",
       "                                 -7.59142637e+00, -7.70741463e+00,             nan,\n",
       "                                             nan, -2.97316337e+00,  5.63122153e-01,\n",
       "                                 -3.35911930e-01,             nan, -1.66767812e+00,\n",
       "                                 -1.92061484e-01, -2.30321229e-01,             nan,\n",
       "                                 -8.16464543e-01, -2.34784889e+00]], dtype=float32),\n",
       "            }),\n",
       "  'linear_1': FlatMap({\n",
       "                'b': DeviceArray([   0.     ,        nan,        nan, ...,    0.     ,\n",
       "                                     0.     , -181.31947], dtype=float32),\n",
       "                'w': DeviceArray([[           nan,            nan,            nan, ...,\n",
       "                                              nan,            nan,            nan],\n",
       "                                  [           nan,            nan,            nan, ...,\n",
       "                                              nan,            nan,            nan],\n",
       "                                  [ 1.2630013e-01,            nan,            nan, ...,\n",
       "                                   -2.5591582e-02,  2.5243817e-03, -1.2800398e+02],\n",
       "                                  ...,\n",
       "                                  [           nan,            nan,            nan, ...,\n",
       "                                              nan,            nan,            nan],\n",
       "                                  [ 8.2243243e-03,            nan,            nan, ...,\n",
       "                                   -1.2625843e-01,  1.4008087e-01, -6.3685493e+00],\n",
       "                                  [-7.8393973e-02,            nan,            nan, ...,\n",
       "                                    1.6253036e-02,  8.0236658e-02, -1.1263333e+02]],            dtype=float32),\n",
       "              }),\n",
       "  'linear_2': FlatMap({\n",
       "                'b': DeviceArray([           nan,            nan,            nan,\n",
       "                                             nan,            nan,            nan,\n",
       "                                             nan,            nan,            nan,\n",
       "                                             nan, -1.7801837e+02,  0.0000000e+00,\n",
       "                                  -1.3390906e+01, -3.7083355e+01,            nan,\n",
       "                                             nan, -1.6112153e+03, -2.3167216e+02,\n",
       "                                  -3.3931763e+02, -3.2822978e+00, -1.0372241e+03,\n",
       "                                  -1.2099336e+03,            nan, -6.5750287e+02,\n",
       "                                  -3.5182183e+03,            nan, -4.5819293e+02,\n",
       "                                             nan, -1.2693406e+02,  0.0000000e+00,\n",
       "                                  -1.2011684e+02,            nan, -1.4129474e+02,\n",
       "                                   0.0000000e+00,            nan,            nan,\n",
       "                                             nan, -9.7576355e+02, -5.4788086e+02,\n",
       "                                  -8.6886536e+02,            nan,  0.0000000e+00,\n",
       "                                             nan, -1.5522914e+03,            nan,\n",
       "                                             nan,  0.0000000e+00,            nan,\n",
       "                                             nan, -5.9763165e+02, -3.0472357e+02,\n",
       "                                             nan,            nan,            nan,\n",
       "                                  -1.3247903e+01, -1.1355929e+02, -3.0703433e+02,\n",
       "                                             nan,  0.0000000e+00,            nan,\n",
       "                                             nan, -3.8409091e+02,  0.0000000e+00,\n",
       "                                   0.0000000e+00,            nan,            nan,\n",
       "                                             nan,            nan,            nan,\n",
       "                                             nan,            nan,  0.0000000e+00,\n",
       "                                  -5.5314349e+02, -7.7665161e+01,            nan,\n",
       "                                             nan,  0.0000000e+00, -1.1038436e+03,\n",
       "                                   0.0000000e+00,  0.0000000e+00,            nan,\n",
       "                                  -3.7571680e+02, -2.6352133e+02,            nan,\n",
       "                                  -5.3622620e+02,            nan, -7.1324186e+00,\n",
       "                                             nan,  0.0000000e+00, -4.7963013e+01,\n",
       "                                  -5.3482361e+01,            nan,            nan,\n",
       "                                   0.0000000e+00, -9.3935814e+01,            nan,\n",
       "                                  -5.5555673e+00,            nan,            nan,\n",
       "                                  -1.3730844e+03,  0.0000000e+00,            nan,\n",
       "                                  -2.3651787e+02,            nan, -6.2001286e+01,\n",
       "                                   0.0000000e+00,            nan,            nan,\n",
       "                                   0.0000000e+00, -1.2776984e+03, -3.2887619e+02,\n",
       "                                             nan,  0.0000000e+00, -1.7218939e+02,\n",
       "                                             nan, -4.2940555e+02,            nan,\n",
       "                                  -2.2344570e+03, -6.9900970e+01,            nan,\n",
       "                                             nan,  0.0000000e+00, -4.9393237e+02,\n",
       "                                   0.0000000e+00,  0.0000000e+00, -1.9922404e+03,\n",
       "                                  -3.8396008e+02,            nan], dtype=float32),\n",
       "                'w': DeviceArray([[nan, nan, nan, ..., nan, nan, nan],\n",
       "                                  [nan, nan, nan, ..., nan, nan, nan],\n",
       "                                  [nan, nan, nan, ..., nan, nan, nan],\n",
       "                                  ...,\n",
       "                                  [nan, nan, nan, ..., nan, nan, nan],\n",
       "                                  [nan, nan, nan, ..., nan, nan, nan],\n",
       "                                  [nan, nan, nan, ..., nan, nan, nan]], dtype=float32),\n",
       "              }),\n",
       "  'linear_3': FlatMap({\n",
       "                'b': DeviceArray([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "                                  nan, nan, nan, nan], dtype=float32),\n",
       "                'w': DeviceArray([[nan, nan, nan, ..., nan, nan, nan],\n",
       "                                  [nan, nan, nan, ..., nan, nan, nan],\n",
       "                                  [nan, nan, nan, ..., nan, nan, nan],\n",
       "                                  ...,\n",
       "                                  [nan, nan, nan, ..., nan, nan, nan],\n",
       "                                  [nan, nan, nan, ..., nan, nan, nan],\n",
       "                                  [nan, nan, nan, ..., nan, nan, nan]], dtype=float32),\n",
       "              }),\n",
       "  'linear_4': FlatMap({\n",
       "                'b': DeviceArray([nan], dtype=float32),\n",
       "                'w': DeviceArray([[nan],\n",
       "                                  [nan],\n",
       "                                  [nan],\n",
       "                                  [nan],\n",
       "                                  [nan],\n",
       "                                  [nan],\n",
       "                                  [nan],\n",
       "                                  [nan],\n",
       "                                  [nan],\n",
       "                                  [nan],\n",
       "                                  [nan],\n",
       "                                  [nan],\n",
       "                                  [nan],\n",
       "                                  [nan],\n",
       "                                  [nan],\n",
       "                                  [nan]], dtype=float32),\n",
       "              }),\n",
       "})"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
